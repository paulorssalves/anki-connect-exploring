{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VER TODO-LIST em README.md\n",
                "import re, os, string, csv\n",
                "import pandas as pd\n",
                "import json, time, urllib.request\n",
                "from tools.tokenization import (get_examples, get_frequency,\n",
                "                    get_text, get_tokens)\n",
                "from requests.exceptions import MissingSchema"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from cltk import NLP\n",
                "from cltk.lemmatize.grc import GreekBackoffLemmatizer\n",
                "lemmatizer = GreekBackoffLemmatizer()\n",
                "\n",
                "from cltk.alphabet.text_normalization import cltk_normalize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tools.wordstruct import Word as WikWord\n",
                "from tools.scraper import Word as BibleWord\n",
                "from tools.scraper import get_link, get_entry_soup, get_word_data, fetch_group_as_string, BASE_URL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ways to perfect this function:\n",
                "# check whether the first word in the concordance example is it\n",
                "# if not, cut off this word (so as to remove incomplete words)\n",
                "# do the same to the last word of the sentence\n",
                "\n",
                "def boldify_selected_word(word, string):\n",
                "    string_l = string.split()\n",
                "    for index in range(len(string_l)):\n",
                "        if string_l[index].lower() == word.lower():\n",
                "            bold = \"<b>\"+word.lower()+\"</b>\"\n",
                "            string_l[index] = bold \n",
                "    return string_l, bold\n",
                "\n",
                "def get_context_and_clean_up(word, concordance):\n",
                "\n",
                "    # get word context from concordance\n",
                "    c = concordance.concordance_list(cltk_normalize(word))\n",
                "\n",
                "    # split string and make chosen word bold\n",
                "    line, bold_word = boldify_selected_word(cltk_normalize(word), c[0][6])\n",
                "    word_list = line\n",
                "\n",
                "    # remove first and last words of string, as they are sometimes incomplete\n",
                "    # and assert that the first and last \n",
                "    if word_list[0] not in (word, bold_word):\n",
                "        del word_list[0]\n",
                "        if word_list[0] in string.punctuation:\n",
                "            del word_list[0] \n",
                "    if word_list[len(word_list) - 1] not in (word, bold_word):\n",
                "        del word_list[len(word_list) - 1]\n",
                "\n",
                "    # get string with extra spaces\n",
                "    unfinished_string = \" \".join(word_list)\n",
                "    \n",
                "    # remove unnecessary spaces from string\n",
                "    trailing_spaces_start = r\"^\\s+\"\n",
                "    trailing_spaces_end = r\"\\s+$\"\n",
                "\n",
                "    cleaned_up_pre = re.sub(r'\\s([?.!,:;\"](?:\\s|$))', r'\\1', unfinished_string)\n",
                "    cleaned_up_start = re.sub(trailing_spaces_start, \"\", cleaned_up_pre)\n",
                "    final_string = re.sub(trailing_spaces_end, \"\", cleaned_up_start)\n",
                "    \n",
                "    return final_string\n",
                "\n",
                "def clean_up(string):\n",
                "    trailing_spaces_start = r\"^\\s+\"\n",
                "    trailing_spaces_end = r\"\\s+$\"\n",
                "\n",
                "    cleaned_up_pre = re.sub(r'([?.!,:;\"](?:\\s|$))', \"\", string.split()[0])\n",
                "    cleaned_up_start = re.sub(trailing_spaces_start, \"\", cleaned_up_pre)\n",
                "    cleaned_up = re.sub(trailing_spaces_end, \"\", cleaned_up_start)\n",
                "\n",
                "    return cleaned_up"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ï„á½¸\n"
                    ]
                }
            ],
            "source": [
                "a = \"Î¤á½¸\".lower()\n",
                "for word in wf.concordance_list(\"Î¤á½¸\")[0][6].split():\n",
                "    if word == a:\n",
                "        print(word)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "â€ğ¤€ CLTK version '1.0.23'.\n",
                        "Pipeline for language 'Ancient Greek' (ISO: 'grc'): `GreekNormalizeProcess`, `GreekStanzaProcess`, `GreekEmbeddingsProcess`, `StopsProcess`, `GreekNERProcess`.\n"
                    ]
                }
            ],
            "source": [
                "songs, wf = get_text(\"textos/apolitikia.txt\")\n",
                "tokens, token_set, phrases = get_tokens(songs)\n",
                "frequency = get_frequency(tokens)\n",
                "cltk_nlp = NLP(language=\"grc\")\n",
                "cltk_doc = cltk_nlp.analyze(songs)\n",
                "\n",
                "wordlist = []\n",
                "for pair in frequency:\n",
                "    token = pair[0]\n",
                "    wordlist.append(token)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def request(action, **params):\n",
                "    return {'action': action,\n",
                "            'params': params,\n",
                "            'version': 6}\n",
                "\n",
                "def invoke(action, **params):\n",
                "    requestJson = json.dumps(request(action, **params)).encode('utf-8')\n",
                "    response = json.load(urllib.request.urlopen(urllib.request.Request('http://localhost:8765', requestJson)))\n",
                "\n",
                "    if len(response) != 2:\n",
                "        raise Exception('response has an unexpected number of fields')\n",
                "\n",
                "    if 'error' not in response:\n",
                "        raise Exception('response is missing required error field')\n",
                "    \n",
                "    if 'result' not in response:\n",
                "        raise Exception('response is missing required result field')\n",
                "\n",
                "    if response['error'] is not None:\n",
                "        raise Exception(response['error'])\n",
                "\n",
                "    return response['result']\n",
                "\n",
                "noteIDs = invoke('findNotes', query='deck:Grego') \n",
                "notesInfo = invoke('notesInfo', notes=noteIDs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_input_for_material(wordlist, anki_cards):\n",
                "\n",
                "    notes = []\n",
                "    for card in anki_cards:\n",
                "        notes.append(cltk_normalize(clean_up(card['fields']['Word']['value'])))\n",
                "    fwl = [cltk_normalize(word) for word in wordlist if word not in notes]\n",
                "    notes_group = lemmatizer.lemmatize(notes)\n",
                "    fwl_group = lemmatizer.lemmatize(fwl)\n",
                "    notes_lemmas = set([tuple[1] for tuple in notes_group])\n",
                "    fwl_lemmas = set([tuple[1] for tuple in fwl_group])\n",
                "\n",
                "    filtered_fwl_lemmas = [word for word in fwl_lemmas if word not in notes_lemmas]\n",
                "    reworked_fwl = [tuple for tuple in fwl_group if tuple[1] in filtered_fwl_lemmas]\n",
                "\n",
                "    for i in range(len(reworked_fwl)):\n",
                "        if reworked_fwl[i][0] == reworked_fwl[i][1]:\n",
                "            reworked_fwl[i] = reworked_fwl[i][0]\n",
                "\n",
                "    return reworked_fwl\n",
                "\n",
                "reworked_fwl = get_input_for_material(wordlist, notesInfo)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "reworked_fwl\n",
                "f = open(\"output/apolitikia.csv\", encoding=\"UTF8\")\n",
                "reader = csv.reader(f)\n",
                "for line in reader:\n",
                "    for entry in reworked_fwl:\n",
                "        if type(entry) == str:\n",
                "            if line[7] == entry:\n",
                "                del reworked_fwl[reworked_fwl.index(entry)]\n",
                "        elif type(entry) == tuple:\n",
                "            if line[7] in (entry[0], entry[1]):\n",
                "                del reworked_fwl[reworked_fwl.index(entry)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def refilter_fwl(list: list, filename: str) -> list:\n",
                "    f = open(os.path.join(\"output\", filename+\".csv\"), encoding=\"UTF8\")\n",
                "    reader = csv.reader(f)\n",
                "    for line in reader:\n",
                "        for entry in list:\n",
                "            if type(entry) == str:\n",
                "                if line[7] == entry:\n",
                "                    del list[list.index(entry)]\n",
                "            elif type(entry) == tuple:\n",
                "                if line[7] in (list[0], list[1]):\n",
                "                    del list[list.index(entry)]\n",
                "\n",
                "reworked_fwl = refilter_fwl(reworked_fwl, \"apolitikia\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['Ï„ÏÎ¹Î®Î¼ÎµÏÎ¿Ï‚',\n",
                            " 'Î¦Î¹Î»Î¬Î½Î¸ÏÏ‰Ï€Îµ',\n",
                            " 'Î•á½Ï†ÏÎ±Î¹Î½Î­ÏƒÎ¸Ï‰',\n",
                            " ('Î¿á½ÏÎ¬Î½Î¹Î±', 'Î¿Ï…Ì“ÏÎ¬Î½Î¹Î¿Ï‚'),\n",
                            " 'á¼˜Ï€Î¬Ï„Î·ÏƒÎµ',\n",
                            " 'Î¤á½¸',\n",
                            " ('Ï†Î±Î¹Î´ÏÏŒÎ½', 'Ï†Î±Î¹Î´ÏÏŒÏ‚'),\n",
                            " 'Ï„Î·Ï‚',\n",
                            " 'á¼ˆÎ½Î±ÏƒÏ„Î¬ÏƒÎµÏ‰Ï‚',\n",
                            " 'ÎºÎ®ÏÏ…Î³Î¼Î±',\n",
                            " 'á¼ˆÎ³Î³Î­Î»Î¿Ï…',\n",
                            " ('Î¼Î±Î¸Î¿á¿¦ÏƒÎ±Î¹', 'Î¼Î±Î½Î¸Î¬Î½Ï‰'),\n",
                            " 'ÎšÏ…ÏÎ¯Î¿Ï…',\n",
                            " 'ÎœÎ±Î¸Î®Ï„ÏÎ¹Î±Î¹',\n",
                            " 'Ï€ÏÎ¿Î³Î¿Î½Î¹Îºá½´Î½',\n",
                            " ('á¼€Ï€ÏŒÏ†Î±ÏƒÎ¹Î½', 'á¼€Ï€ÏŒÏ†Î±ÏƒÎ¹Ï‚'),\n",
                            " ('á¼€Ï€Î¿ÏÏÎ¯ÏˆÎ±ÏƒÎ±Î¹', 'á¼€Ï€Î¿ÏÏÎ¯Ï€Ï„Ï‰'),\n",
                            " ('ÎºÎ±Ï…Ï‡ÏÎ¼ÎµÎ½Î±Î¹', 'ÎºÎ±Ï…Ï‡Î¬Î¿Î¼Î±Î¹'),\n",
                            " 'á¼˜ÏƒÎºÏÎ»ÎµÏ…Ï„Î±Î¹',\n",
                            " 'Î§ÏÎ¹ÏƒÏ„á½¸Ï‚',\n",
                            " 'Î¤á½¸Î½',\n",
                            " ('ÏƒÏ…Î½Î¬Î½Î±ÏÏ‡Î¿Î½', 'ÏƒÏÎ½,á¼€Î½Î¬á¼„ÏÏ‡Ï‰'),\n",
                            " 'Î›ÏŒÎ³Î¿Î½',\n",
                            " 'Î Î±Ï„Ïá½¶',\n",
                            " 'Î Î½ÎµÏÎ¼Î±Ï„Î¹',\n",
                            " 'Î Î±ÏÎ¸Î­Î½Î¿Ï…',\n",
                            " ('á¼€Î½Î±Î¼Î½Î®ÏƒÏ‰Î¼ÎµÎ½', 'á¼€Î½Î±Î¼Î¹Î¼Î½Î®ÏƒÎºÏ‰'),\n",
                            " ('Î·á½Î´ÏŒÎºÎ·ÏƒÎµ', 'ÎµÏ…Ì“Î´Î¿ÎºÎ­Ï‰'),\n",
                            " ('á½‘Ï€Î¿Î¼Îµá¿–Î½Î±Î¹', 'á½‘Ï€Î¿Î¼Î­Î½Ï‰'),\n",
                            " 'á¼ˆÎ³Î³ÎµÎ»Î¹ÎºÎ±á½¶',\n",
                            " ('á¼€Ï€ÎµÎ½ÎµÎºÏÏÎ¸Î·ÏƒÎ±Î½', 'á¼€Ï€ÏŒÎ½ÎµÎºÏÏŒÏ‰'),\n",
                            " ('Î¶Î·Ï„Î¿á¿¦ÏƒÎ±', 'Î¶Î·Ï„Î­Ï‰'),\n",
                            " 'á¼˜ÏƒÎºÏÎ»ÎµÏ…ÏƒÎ±Ï‚',\n",
                            " 'Ï€ÎµÎ¹ÏÎ±ÏƒÎ¸Îµá½¶Ï‚',\n",
                            " ('á½‘Ï€', 'á½‘Ï€ÏŒ'),\n",
                            " 'á½™Ï€Î®Î½Ï„Î·ÏƒÎ±Ï‚',\n",
                            " 'Î Î±ÏÎ¸Î­Î½á¿³',\n",
                            " 'ÎšÎ±Ï„Î­Î»Ï…ÏƒÎ±Ï‚',\n",
                            " 'á¼ Î½Î­Ï‰Î¾Î±Ï‚',\n",
                            " 'Î›Î·ÏƒÏ„á¿‡',\n",
                            " 'Î Î±ÏÎ¬Î´ÎµÎ¹ÏƒÎ¿Î½',\n",
                            " 'ÎœÏ…ÏÎ¿Ï†ÏŒÏÏ‰Î½',\n",
                            " ('Î¼ÎµÏ„Î­Î²Î±Î»ÎµÏ‚', 'Î¼ÎµÏ„Î±Î²Î¬Î»Î»Ï‰'),\n",
                            " ('ÎºÎ·ÏÏÏ„Ï„ÎµÎ¹Î½', 'ÎºÎ·ÏÏÏƒÏƒÏ‰'),\n",
                            " ('Ï€Î±ÏÎ­Ï‡Ï‰Î½', 'Ï€Î±ÏÎ­Ï‡Ï‰'),\n",
                            " 'á¼˜Î¾',\n",
                            " ('á½•ÏˆÎ¿Ï…Ï‚', 'á½•ÏˆÎ¿Ï‚'),\n",
                            " ('Îµá½”ÏƒÏ€Î»Î±Î³Ï‡Î½Î¿Ï‚', 'ÎµÏ…Ì“ÌÏƒÏ€Î»Î±Î³Ï‡Î½Î¿Ï‚'),\n",
                            " 'Ï„Î±Ï†á½´Î½',\n",
                            " ('ÎºÎ±Ï„ÎµÎ´Î­Î¾Ï‰', 'ÎºÎ±Ï„Î±Î´ÎµÎ¯ÎºÎ½Ï…Î¼Î¹'),\n",
                            " ('Ï„ÏÎ¹Î®Î¼ÎµÏÎ¿Î½', 'Ï„ÏÎ¹Î®Î¼ÎµÏÎ¿Ï‚'),\n",
                            " 'á¼Î»ÎµÏ…Î¸ÎµÏÏÏƒÎ·Ï‚',\n",
                            " ('Ï€Î±Î¸á¿¶Î½', 'Ï€Î¬Î¸Î¿Ï‚'),\n",
                            " 'á¼ˆÎ½Î¬ÏƒÏ„Î±ÏƒÎ¹Ï‚',\n",
                            " 'á¼„Ï‡ÏÎ±Î½Ï„ÏŒÎ½',\n",
                            " 'Î£á¿¶Î¼Î±',\n",
                            " 'Î£Î¿Î¹',\n",
                            " 'Î–Ï‰Î¿Î´ÏŒÏ„Î±',\n",
                            " 'á¼ˆÎ½Î±ÏƒÏ„Î¬ÏƒÎµÎ¹',\n",
                            " 'á½Ï„Îµ',\n",
                            " 'Î¶Ï‰á½´',\n",
                            " ('á¼„Î´Î·Î½', 'á¼…Î´Î·Î½'),\n",
                            " ('Ï„ÎµÎ¸Î½Îµá¿¶Ï„Î±Ï‚', 'Î¸Î½Î®ÏƒÎºÏ‰'),\n",
                            " 'Î§ÏÎ¹ÏƒÏ„á½²',\n",
                            " 'á¼ˆÏ€Î¿ÏƒÏ„ÏŒÎ»Î¿Î¹Ï‚',\n",
                            " 'Î£Ï„Î±Ï…Ïá¿·',\n",
                            " 'Î£Î¿Ï…',\n",
                            " 'Î”Ï…Î½Î¬Î¼ÎµÎ¹Ï‚']"
                        ]
                    },
                    "execution_count": 41,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "reworked_fwl"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "def fetch_bible_word(word):\n",
                "    link = get_link(BASE_URL, word)\n",
                "    soup = get_entry_soup(link)\n",
                "    word = BibleWord(get_word_data(soup))\n",
                "\n",
                "    return word"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "def searcher(word):\n",
                "\n",
                "    if type(word) == tuple:\n",
                "        try:\n",
                "            bible_word = fetch_bible_word(word[0])\n",
                "            return {\"search_num\": 1, \"source\": \"BibleHub\", \"input\": word[0], \"output\": bible_word.data}\n",
                "\n",
                "        except MissingSchema:\n",
                "            try:\n",
                "                bible_word = fetch_bible_word(word[1])\n",
                "                return {\"search_num\": 2, \"source\": \"BibleHub\", \"input\": word[0], \"output\": bible_word.data}\n",
                "\n",
                "            except MissingSchema:\n",
                "\n",
                "                return {\"search_num\": 2, \"source\": None, \"input\": word[0], \"output\": None}\n",
                "                \n",
                "\n",
                "    elif type(word) == str:\n",
                "        try: \n",
                "            bible_word = fetch_bible_word(word)\n",
                "            return {\"search_num\": 1, \"source\": \"BibleHub\", \"input\": word, \"output\": bible_word.data}\n",
                "\n",
                "        except:\n",
                "                return {\"search_num\": 1, \"source\": None, \"input\": word, \"output\": None}\n",
                "\n",
                "    else:\n",
                "\n",
                "        return {\"search_num\": 0, \"source\": None, \"input\": word, \"output\": None}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "word no. 1: á½‰Î´Î¿á½¶\n",
                        "word no. 2: ('Î´Î¹Î±Ï†Î¿Ïá½°', 'Î´Î¹Î±Ï†Î¿ÏÎ¬')\n",
                        "word no. 3: ÏƒÎµÎ±Ï…Ï„ÏŒÎ½Â·\n",
                        "word no. 4: Î³Î¯Î½ÎµÏƒÎ¸Î±Î¯\n",
                        "word no. 5: ('[', 'punc')\n",
                        "word no. 6: Î•á½Î»Î¿Î³Îµá¿–Ï„Îµ\n",
                        "word no. 7: á½‘Î¼á¾¶Ï‚Â·\n",
                        "word no. 8: ÎŸá½Ï‡á½¶\n",
                        "Wait... 0/60\n",
                        "Wait... 1/60\n",
                        "Wait... 2/60\n",
                        "Wait... 3/60\n",
                        "Wait... 4/60\n",
                        "Wait... 5/60\n",
                        "Wait... 6/60\n",
                        "Wait... 7/60\n",
                        "Wait... 8/60\n",
                        "Wait... 9/60\n",
                        "Wait... 10/60\n",
                        "Wait... 11/60\n",
                        "Wait... 12/60\n",
                        "Wait... 13/60\n",
                        "Wait... 14/60\n",
                        "Wait... 15/60\n",
                        "Wait... 16/60\n",
                        "Wait... 17/60\n",
                        "Wait... 18/60\n",
                        "Wait... 19/60\n",
                        "Wait... 20/60\n",
                        "Wait... 21/60\n",
                        "Wait... 22/60\n",
                        "Wait... 23/60\n",
                        "Wait... 24/60\n",
                        "Wait... 25/60\n",
                        "Wait... 26/60\n",
                        "Wait... 27/60\n",
                        "Wait... 28/60\n",
                        "Wait... 29/60\n",
                        "Wait... 30/60\n",
                        "Wait... 31/60\n",
                        "Wait... 32/60\n",
                        "Wait... 33/60\n",
                        "Wait... 34/60\n",
                        "Wait... 35/60\n",
                        "Wait... 36/60\n",
                        "Wait... 37/60\n",
                        "Wait... 38/60\n",
                        "Wait... 39/60\n",
                        "Wait... 40/60\n",
                        "Wait... 41/60\n",
                        "Wait... 42/60\n",
                        "Wait... 43/60\n",
                        "Wait... 44/60\n",
                        "Wait... 45/60\n",
                        "Wait... 46/60\n",
                        "Wait... 47/60\n",
                        "Wait... 48/60\n",
                        "Wait... 49/60\n",
                        "Wait... 50/60\n",
                        "Wait... 51/60\n",
                        "Wait... 52/60\n",
                        "Wait... 53/60\n",
                        "Wait... 54/60\n",
                        "Wait... 55/60\n",
                        "Wait... 56/60\n",
                        "Wait... 57/60\n",
                        "Wait... 58/60\n",
                        "Wait... 59/60\n"
                    ]
                }
            ],
            "source": [
                "# Ã‰ necessÃ¡rio criar alguma forma de verificar se\n",
                "# as palavras que o script adquiriu correspondem Ã s palavras\n",
                "# do input, uma vez que as palavras obtidas do BibleHub podem ser,\n",
                "# devido ao meu algoritmo meio porco, nÃ£o muito confiÃ¡veis\n",
                "\n",
                "# uma ideia interessante seria adicionar um marcador ao lado, algo como \n",
                "\n",
                "# Mais uma coisa a aperfeiÃ§oar:\n",
                "# Se a mesma palavra jÃ¡ estiver presente, deixar de lado\n",
                "# nÃ£o o mesmo radical, mas *a mesma palavra*\n",
                "\n",
                "def acquire_data(list, amount=None):\n",
                "\n",
                "    bible_searches = 0\n",
                "    data = []\n",
                "    blanks = []\n",
                "    already_present = []\n",
                "\n",
                "    if (amount != None) and (amount <= len(list)):\n",
                "        number = range(amount)\n",
                "    else:\n",
                "        number = range(len(list))\n",
                "\n",
                "    for index in number:\n",
                "        print(\"word no. {}: {}\".format(index+1, list[index]))\n",
                "        word_dict = searcher(list[index])\n",
                "\n",
                "        if word_dict[\"source\"] != None:\n",
                "            result = (word_dict[\"source\"], word_dict[\"input\"], word_dict[\"output\"])\n",
                "            if result[2] not in already_present:\n",
                "                data.append(result)\n",
                "            already_present.append(result[2])\n",
                "        else:\n",
                "            blanks.append(word_dict[\"input\"])\n",
                "\n",
                "        bible_searches += word_dict[\"search_num\"]\n",
                "\n",
                "        if bible_searches >= 10:\n",
                "            for n in range(60):\n",
                "                time.sleep(1)\n",
                "                print(\"Wait... {}/60\".format(n))\n",
                "                bible_searches = 0\n",
                "    \n",
                "    return data, blanks\n",
                "\n",
                "data, blanks = acquire_data(reworked_fwl,8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "á½‰Î´Î¿á½¶\n",
                        "Î•á½Î»Î¿Î³Îµá¿–Ï„Îµ\n",
                        "ÎŸá½Ï‡á½¶\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "def produce_material(output_file_name, data=None, blanks=None):\n",
                "    if type(output_file_name) is not str:\n",
                "        raise TypeError(\"variable 'output_file_name' must be of type 'str'.\")\n",
                "\n",
                "    if (data is not None) and (data != []): \n",
                "        for item in data:\n",
                "            if item[0] is not None:\n",
                "\n",
                "                print(item[1])\n",
                "\n",
                "                curr = item[2]\n",
                "                concordances = curr[\"concordances\"]\n",
                "\n",
                "                dc = {\n",
                "                    \"word\": clean_up(concordances[\"Original Word\"]),\n",
                "                    \"phonetics\": concordances[\"Phonetic Spelling\"],\n",
                "                    \"category\": concordances[\"Part of Speech\"],\n",
                "                    \"meaning\": concordances['Definition'],\n",
                "                    \"greek\": fetch_group_as_string([tuple[0] for tuple in curr['examples']], single_list=True),\n",
                "                    \"english\": fetch_group_as_string([tuple[1] for tuple in curr['examples']], single_list=True)\n",
                "                }\n",
                "                dc[\"context\"] = \"\\\"\"+get_context_and_clean_up(item[1], wf)+\"\\\"\"\n",
                "                dc[\"original\"] = item[1]        \n",
                "                dc[\"source\"] = item[0]        \n",
                "                # to display which word is being worked upon at the time\n",
                "\n",
                "                words_dataframe = pd.DataFrame.from_dict(dc, orient=\"index\")\n",
                "                words_dataframe = words_dataframe.transpose()\n",
                "                words_dataframe.to_csv(os.path.join(\"output\", output_file_name+\".csv\"), \n",
                "                                                    encoding=\"utf-8\", mode=\"a\", \n",
                "                                                    header=False, index=False)\n",
                "            \n",
                "    if (blanks is not None) and (blanks != []):\n",
                "        blanks_dataframe = pd.DataFrame(blanks)\n",
                "        blanks_dataframe= blanks_dataframe.transpose()\n",
                "        blanks_dataframe.to_csv(os.path.join(\"blanks\", output_file_name+\"_blanks.csv\"), \n",
                "                                            encoding=\"utf-8\", mode=\"a\", \n",
                "                                            header=False, index=False)\n",
                "\n",
                "produce_material(\"test\", data=data, blanks=None)\n",
                "regex = re.compile(\"\\\"\\\"\")\n",
                "with open(os.path.join(\"output\", \"test.csv\")) as file:\n",
                "    for line in file:\n",
                "        regex.sub(\"\", line)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "word no. 1: á½‰Î´Î¿á½¶\n",
                        "word no. 2: ('Î´Î¹Î±Ï†Î¿Ïá½°', 'Î´Î¹Î±Ï†Î¿ÏÎ¬')\n",
                        "word no. 3: ÏƒÎµÎ±Ï…Ï„ÏŒÎ½Â·\n",
                        "word no. 4: Î³Î¯Î½ÎµÏƒÎ¸Î±Î¯\n",
                        "word no. 5: ('[', 'punc')\n",
                        "word no. 6: Î•á½Î»Î¿Î³Îµá¿–Ï„Îµ\n"
                    ]
                }
            ],
            "source": [
                "d = acquire_data(reworked_fwl[0:6])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "([('BibleHub',\n",
                            "   'á½‰Î´Î¿á½¶',\n",
                            "   {'concordances': {'Original Word': 'á½Î´ÏŒÏ‚, Î¿á¿¦, á¼¡',\n",
                            "     'Part of Speech': 'Noun, Feminine',\n",
                            "     'Transliteration': 'hodos',\n",
                            "     'Phonetic Spelling': \"(hod-os')\",\n",
                            "     'Definition': 'a way, road',\n",
                            "     'Usage': 'a way, road, journey, path.'},\n",
                            "    'examples': [('á¼™Ï„Î¿Î¹Î¼Î¬ÏƒÎ±Ï„Îµ Ï„á½´Î½ á½Î´á½¸Î½ ÎšÏ…ÏÎ¯Î¿Ï… Îµá½Î¸ÎµÎ¯Î±Ï‚',\n",
                            "      ' Prepare the way of [the] Lord straight'),\n",
                            "     ('Î³á¿† ÎÎµÏ†Î¸Î±Î»Î¯Î¼ á½Î´á½¸Î½ Î¸Î±Î»Î¬ÏƒÏƒÎ·Ï‚ Ï€Î­ÏÎ±Î½',\n",
                            "      ' land of Naphtali way of [the] sea beyond'),\n",
                            "     ('á¼Î½ Ï„á¿‡ á½Î´á¿· Î¼Î® Ï€Î¿Ï„Î­', ' on the way lest ever')]}),\n",
                            "  ('BibleHub',\n",
                            "   'Î•á½Î»Î¿Î³Îµá¿–Ï„Îµ',\n",
                            "   {'concordances': {'Original Word': 'Îµá½Î»Î¿Î³Î­Ï‰',\n",
                            "     'Part of Speech': 'Verb',\n",
                            "     'Transliteration': 'eulogeÃ³',\n",
                            "     'Phonetic Spelling': \"(yoo-log-eh'-o)\",\n",
                            "     'Definition': 'to speak well of, praise',\n",
                            "     'Usage': '(lit: I speak well of) I bless; pass: I am blessed.'},\n",
                            "    'examples': [('Ï„á½¸Î½ Î¿á½ÏÎ±Î½á½¸Î½ Îµá½Î»ÏŒÎ³Î·ÏƒÎµÎ½ ÎºÎ±á½¶ ÎºÎ»Î¬ÏƒÎ±Ï‚',\n",
                            "      ' heaven he blessed and having broken'),\n",
                            "     ('Ï…á¼±á¿· Î”Î±Ï…Î¯Î´ Î•á½Î»Î¿Î³Î·Î¼Î­Î½Î¿Ï‚ á½ á¼ÏÏ‡ÏŒÎ¼ÎµÎ½Î¿Ï‚',\n",
                            "      ' Son of David blessed [is] he who comes'),\n",
                            "     ('á¼‚Î½ Îµá¼´Ï€Î·Ï„Îµ Î•á½Î»Î¿Î³Î·Î¼Î­Î½Î¿Ï‚ á½ á¼ÏÏ‡ÏŒÎ¼ÎµÎ½Î¿Ï‚',\n",
                            "      ' anyhow you say Blessed [is] he who comes')]})],\n",
                            " ['Î´Î¹Î±Ï†Î¿Ïá½°', 'ÏƒÎµÎ±Ï…Ï„ÏŒÎ½Â·', 'Î³Î¯Î½ÎµÏƒÎ¸Î±Î¯', '['])"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "d"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "('BibleHub', 'Î•á½Î»Î¿Î³Îµá¿–Ï„Îµ', {'concordances': {'Original Word': 'Îµá½Î»Î¿Î³Î­Ï‰', 'Part of Speech': 'Verb', 'Transliteration': 'eulogeÃ³', 'Phonetic Spelling': \"(yoo-log-eh'-o)\", 'Definition': 'to speak well of, praise', 'Usage': '(lit: I speak well of) I bless; pass: I am blessed.'}, 'examples': [('Ï„á½¸Î½ Î¿á½ÏÎ±Î½á½¸Î½ Îµá½Î»ÏŒÎ³Î·ÏƒÎµÎ½ ÎºÎ±á½¶ ÎºÎ»Î¬ÏƒÎ±Ï‚', ' heaven he blessed and having broken'), ('Ï…á¼±á¿· Î”Î±Ï…Î¯Î´ Î•á½Î»Î¿Î³Î·Î¼Î­Î½Î¿Ï‚ á½ á¼ÏÏ‡ÏŒÎ¼ÎµÎ½Î¿Ï‚', ' Son of David blessed [is] he who comes'), ('á¼‚Î½ Îµá¼´Ï€Î·Ï„Îµ Î•á½Î»Î¿Î³Î·Î¼Î­Î½Î¿Ï‚ á½ á¼ÏÏ‡ÏŒÎ¼ÎµÎ½Î¿Ï‚', ' anyhow you say Blessed [is] he who comes')]})\n"
                    ]
                },
                {
                    "ename": "IndexError",
                    "evalue": "list index out of range",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-16-2f0a5bbe466a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproduce_material\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"didache\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m<ipython-input-13-49f4370ada93>\u001b[0m in \u001b[0;36mproduce_material\u001b[0;34m(output_file_name, data, blanks)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0mconcordances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"concordances\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
                    ]
                }
            ],
            "source": [
                "produce_material(\"didache\", d)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[('BibleHub', 'Î´ÏÎ¿', {'concordances': {'Original Word': 'Î´ÏÎ¿', 'Part of Speech': 'Adjective; Indeclinable Numeral (Adjective)', 'Transliteration': 'duo', 'Phonetic Spelling': \"(doo'-o)\", 'Definition': 'two', 'Usage': 'two.'}, 'examples': [('Îµá¼¶Î´ÎµÎ½ á¼„Î»Î»Î¿Ï…Ï‚ Î´ÏÎ¿ á¼€Î´ÎµÎ»Ï†Î¿ÏÏ‚ á¼¸Î¬ÎºÏ‰Î²Î¿Î½', ' he saw others two brothers James'), (\"Î¼ÎµÏ„' Î±á½Ï„Î¿á¿¦ Î´ÏÎ¿ \", ' with him two'), ('ÎŸá½Î´Îµá½¶Ï‚ Î´ÏÎ½Î±Ï„Î±Î¹ Î´Ï…Ïƒá½¶ ÎºÏ…ÏÎ¯Î¿Î¹Ï‚ Î´Î¿Ï…Î»ÎµÏÎµÎ¹Î½', ' No one is able two masters to serve')]}), ('BibleHub', 'á¼±Î¼Î¬Ï„Î¹ÏŒÎ½', {'concordances': {'Original Word': 'á¼±Î¼Î¬Ï„Î¹Î¿Î½, Î¿Ï…, Ï„ÏŒ', 'Part of Speech': 'Noun, Neuter', 'Transliteration': 'himation', 'Phonetic Spelling': \"(him-at'-ee-on)\", 'Definition': 'an outer garment, a cloak, robe', 'Usage': ' a long flowing outer garment, tunic.'}, 'examples': [('á¼€Î³Î½Î¬Ï†Î¿Ï… á¼Ï€á½¶ á¼±Î¼Î±Ï„Î¯á¿³ Ï€Î±Î»Î±Î¹á¿· Î±á¼´ÏÎµÎ¹', ' unshrunk on clothing old tears away'), ('á¼€Ï€á½¸ Ï„Î¿á¿¦ á¼±Î¼Î±Ï„Î¯Î¿Ï… ÎºÎ±á½¶ Ï‡Îµá¿–ÏÎ¿Î½', ' from the garment and a worse'), ('ÎºÏÎ±ÏƒÏ€Î­Î´Î¿Ï… Ï„Î¿á¿¦ á¼±Î¼Î±Ï„Î¯Î¿Ï… Î±á½Ï„Î¿á¿¦ ', ' fringe of the clothing of him')]}), ('BibleHub', 'Ï‡Î¹Ï„á¿¶Î½Î±', {'concordances': {'Original Word': 'Ï‡Î¹Ï„ÏÎ½, á¿¶Î½Î¿Ï‚, á½', 'Part of Speech': 'Noun, Masculine', 'Transliteration': 'chitÃ³n', 'Phonetic Spelling': \"(khee-tone')\", 'Definition': 'a tunic', 'Usage': 'a tunic, garment, undergarment.'}, 'examples': [('Î¼Î·Î´á½² Î´ÏÎ¿ Ï‡Î¹Ï„á¿¶Î½Î±Ï‚ Î¼Î·Î´á½² á½‘Ï€Î¿Î´Î®Î¼Î±Ï„Î±', ' nor two tunics nor sandals'), ('á¼Î½Î´ÏÏƒÎ·ÏƒÎ¸Îµ Î´ÏÎ¿ Ï‡Î¹Ï„á¿¶Î½Î±Ï‚ ', ' put on two tunics'), ('Î´Î¹Î±ÏÏÎ®Î¾Î±Ï‚ Ï„Î¿á½ºÏ‚ Ï‡Î¹Ï„á¿¶Î½Î±Ï‚ Î±á½Ï„Î¿á¿¦ Î»Î­Î³ÎµÎ¹', ' having torn the garments of him says')]}), ('BibleHub', 'Î»Î¬Î²á¿ƒ', {'concordances': {'Original Word': 'Î»Î±Î¼Î²Î¬Î½Ï‰', 'Part of Speech': 'Verb', 'Transliteration': 'lambanÃ³', 'Phonetic Spelling': \"(lam-ban'-o)\", 'Definition': 'to take, receive', 'Usage': '(a) I receive, get, (b) I take, lay hold of.'}, 'examples': [('á½ Î±á¼°Ï„á¿¶Î½ Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ ÎºÎ±á½¶ á½', ' who asks receives and he that'), ('á¼€ÏƒÎ¸ÎµÎ½ÎµÎ¯Î±Ï‚ á¼¡Î¼á¿¶Î½ á¼”Î»Î±Î²ÎµÎ½ ÎºÎ±á½¶ Ï„á½°Ï‚', ' infirmities of us he took and our'), ('á¼ÎºÎ²Î¬Î»Î»ÎµÏ„Îµ Î´Ï‰ÏÎµá½°Î½ á¼Î»Î¬Î²ÎµÏ„Îµ Î´Ï‰ÏÎµá½°Î½ Î´ÏŒÏ„Îµ', ' cast out freely you received freely give')]}), ('BibleHub', 'Î¿á½Î´á½²', {'concordances': {'Original Word': 'Î¿á½Î´Î­', 'Part of Speech': 'Conjunction,Negative', 'Transliteration': 'oude', 'Phonetic Spelling': \"(oo-deh')\", 'Definition': 'and not, neither', 'Usage': 'neither, nor, not even, and not.'}, 'examples': [('Ï€Î±ÏÎ±Ï€Ï„ÏÎ¼Î±Ï„Î± Î±á½Ï„á¿¶Î½ Î¿á½Î´á½² á½ Ï€Î±Ï„á½´Ï', ' trespasses of them neither the Father'), ('Î¿á½ Î´Î¹Î¿ÏÏÏƒÏƒÎ¿Ï…ÏƒÎ¹Î½ Î¿á½Î´á½² ÎºÎ»Î­Ï€Ï„Î¿Ï…ÏƒÎ¹Î½ ', ' not do break in nor steal'), ('Î¿á½ ÏƒÏ€ÎµÎ¯ÏÎ¿Ï…ÏƒÎ¹Î½ Î¿á½Î´á½² Î¸ÎµÏÎ¯Î¶Î¿Ï…ÏƒÎ¹Î½ Î¿á½Î´á½²', ' not they sow nor do they reap nor')]}), ('BibleHub', 'Î Î±Î½Ï„á½¶', {'concordances': {'Original Word': 'Ï€á¾¶Ï‚, Ï€á¾¶ÏƒÎ±, Ï€á¾¶Î½', 'Part of Speech': 'Adjective', 'Transliteration': 'pas', 'Phonetic Spelling': '(pas)', 'Definition': 'all, every', 'Usage': 'all, the whole, every kind of.'}, 'examples': [(\"á¼Ï„Î±ÏÎ¬Ï‡Î¸Î· ÎºÎ±á½¶ Ï€á¾¶ÏƒÎ± á¼¸ÎµÏÎ¿ÏƒÏŒÎ»Ï…Î¼Î± Î¼ÎµÏ„'\", ' he was troubled and all Jerusalem with'), ('ÎºÎ±á½¶ ÏƒÏ…Î½Î±Î³Î±Î³á½¼Î½ Ï€Î¬Î½Ï„Î±Ï‚ Ï„Î¿á½ºÏ‚ á¼€ÏÏ‡Î¹ÎµÏÎµá¿–Ï‚', ' And having gathered together all the chief priests'), ('á¼€Ï€Î¿ÏƒÏ„ÎµÎ¯Î»Î±Ï‚ á¼€Î½Îµá¿–Î»ÎµÎ½ Ï€Î¬Î½Ï„Î±Ï‚ Ï„Î¿á½ºÏ‚ Ï€Î±á¿–Î´Î±Ï‚', ' having sent forth he put to death all the boys')]})]\n",
                        "[('BibleHub', 'Î´ÏÎ¿', {'concordances': {'Original Word': 'Î´ÏÎ¿', 'Part of Speech': 'Adjective; Indeclinable Numeral (Adjective)', 'Transliteration': 'duo', 'Phonetic Spelling': \"(doo'-o)\", 'Definition': 'two', 'Usage': 'two.'}, 'examples': [('Îµá¼¶Î´ÎµÎ½ á¼„Î»Î»Î¿Ï…Ï‚ Î´ÏÎ¿ á¼€Î´ÎµÎ»Ï†Î¿ÏÏ‚ á¼¸Î¬ÎºÏ‰Î²Î¿Î½', ' he saw others two brothers James'), (\"Î¼ÎµÏ„' Î±á½Ï„Î¿á¿¦ Î´ÏÎ¿ \", ' with him two'), ('ÎŸá½Î´Îµá½¶Ï‚ Î´ÏÎ½Î±Ï„Î±Î¹ Î´Ï…Ïƒá½¶ ÎºÏ…ÏÎ¯Î¿Î¹Ï‚ Î´Î¿Ï…Î»ÎµÏÎµÎ¹Î½', ' No one is able two masters to serve')]}), ('BibleHub', 'á¼±Î¼Î¬Ï„Î¹ÏŒÎ½', {'concordances': {'Original Word': 'á¼±Î¼Î¬Ï„Î¹Î¿Î½, Î¿Ï…, Ï„ÏŒ', 'Part of Speech': 'Noun, Neuter', 'Transliteration': 'himation', 'Phonetic Spelling': \"(him-at'-ee-on)\", 'Definition': 'an outer garment, a cloak, robe', 'Usage': ' a long flowing outer garment, tunic.'}, 'examples': [('á¼€Î³Î½Î¬Ï†Î¿Ï… á¼Ï€á½¶ á¼±Î¼Î±Ï„Î¯á¿³ Ï€Î±Î»Î±Î¹á¿· Î±á¼´ÏÎµÎ¹', ' unshrunk on clothing old tears away'), ('á¼€Ï€á½¸ Ï„Î¿á¿¦ á¼±Î¼Î±Ï„Î¯Î¿Ï… ÎºÎ±á½¶ Ï‡Îµá¿–ÏÎ¿Î½', ' from the garment and a worse'), ('ÎºÏÎ±ÏƒÏ€Î­Î´Î¿Ï… Ï„Î¿á¿¦ á¼±Î¼Î±Ï„Î¯Î¿Ï… Î±á½Ï„Î¿á¿¦ ', ' fringe of the clothing of him')]}), ('BibleHub', 'Ï‡Î¹Ï„á¿¶Î½Î±', {'concordances': {'Original Word': 'Ï‡Î¹Ï„ÏÎ½, á¿¶Î½Î¿Ï‚, á½', 'Part of Speech': 'Noun, Masculine', 'Transliteration': 'chitÃ³n', 'Phonetic Spelling': \"(khee-tone')\", 'Definition': 'a tunic', 'Usage': 'a tunic, garment, undergarment.'}, 'examples': [('Î¼Î·Î´á½² Î´ÏÎ¿ Ï‡Î¹Ï„á¿¶Î½Î±Ï‚ Î¼Î·Î´á½² á½‘Ï€Î¿Î´Î®Î¼Î±Ï„Î±', ' nor two tunics nor sandals'), ('á¼Î½Î´ÏÏƒÎ·ÏƒÎ¸Îµ Î´ÏÎ¿ Ï‡Î¹Ï„á¿¶Î½Î±Ï‚ ', ' put on two tunics'), ('Î´Î¹Î±ÏÏÎ®Î¾Î±Ï‚ Ï„Î¿á½ºÏ‚ Ï‡Î¹Ï„á¿¶Î½Î±Ï‚ Î±á½Ï„Î¿á¿¦ Î»Î­Î³ÎµÎ¹', ' having torn the garments of him says')]}), ('BibleHub', 'Î»Î¬Î²á¿ƒ', {'concordances': {'Original Word': 'Î»Î±Î¼Î²Î¬Î½Ï‰', 'Part of Speech': 'Verb', 'Transliteration': 'lambanÃ³', 'Phonetic Spelling': \"(lam-ban'-o)\", 'Definition': 'to take, receive', 'Usage': '(a) I receive, get, (b) I take, lay hold of.'}, 'examples': [('á½ Î±á¼°Ï„á¿¶Î½ Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ ÎºÎ±á½¶ á½', ' who asks receives and he that'), ('á¼€ÏƒÎ¸ÎµÎ½ÎµÎ¯Î±Ï‚ á¼¡Î¼á¿¶Î½ á¼”Î»Î±Î²ÎµÎ½ ÎºÎ±á½¶ Ï„á½°Ï‚', ' infirmities of us he took and our'), ('á¼ÎºÎ²Î¬Î»Î»ÎµÏ„Îµ Î´Ï‰ÏÎµá½°Î½ á¼Î»Î¬Î²ÎµÏ„Îµ Î´Ï‰ÏÎµá½°Î½ Î´ÏŒÏ„Îµ', ' cast out freely you received freely give')]}), ('BibleHub', 'Î¿á½Î´á½²', {'concordances': {'Original Word': 'Î¿á½Î´Î­', 'Part of Speech': 'Conjunction,Negative', 'Transliteration': 'oude', 'Phonetic Spelling': \"(oo-deh')\", 'Definition': 'and not, neither', 'Usage': 'neither, nor, not even, and not.'}, 'examples': [('Ï€Î±ÏÎ±Ï€Ï„ÏÎ¼Î±Ï„Î± Î±á½Ï„á¿¶Î½ Î¿á½Î´á½² á½ Ï€Î±Ï„á½´Ï', ' trespasses of them neither the Father'), ('Î¿á½ Î´Î¹Î¿ÏÏÏƒÏƒÎ¿Ï…ÏƒÎ¹Î½ Î¿á½Î´á½² ÎºÎ»Î­Ï€Ï„Î¿Ï…ÏƒÎ¹Î½ ', ' not do break in nor steal'), ('Î¿á½ ÏƒÏ€ÎµÎ¯ÏÎ¿Ï…ÏƒÎ¹Î½ Î¿á½Î´á½² Î¸ÎµÏÎ¯Î¶Î¿Ï…ÏƒÎ¹Î½ Î¿á½Î´á½²', ' not they sow nor do they reap nor')]}), ('BibleHub', 'Î Î±Î½Ï„á½¶', {'concordances': {'Original Word': 'Ï€á¾¶Ï‚, Ï€á¾¶ÏƒÎ±, Ï€á¾¶Î½', 'Part of Speech': 'Adjective', 'Transliteration': 'pas', 'Phonetic Spelling': '(pas)', 'Definition': 'all, every', 'Usage': 'all, the whole, every kind of.'}, 'examples': [(\"á¼Ï„Î±ÏÎ¬Ï‡Î¸Î· ÎºÎ±á½¶ Ï€á¾¶ÏƒÎ± á¼¸ÎµÏÎ¿ÏƒÏŒÎ»Ï…Î¼Î± Î¼ÎµÏ„'\", ' he was troubled and all Jerusalem with'), ('ÎºÎ±á½¶ ÏƒÏ…Î½Î±Î³Î±Î³á½¼Î½ Ï€Î¬Î½Ï„Î±Ï‚ Ï„Î¿á½ºÏ‚ á¼€ÏÏ‡Î¹ÎµÏÎµá¿–Ï‚', ' And having gathered together all the chief priests'), ('á¼€Ï€Î¿ÏƒÏ„ÎµÎ¯Î»Î±Ï‚ á¼€Î½Îµá¿–Î»ÎµÎ½ Ï€Î¬Î½Ï„Î±Ï‚ Ï„Î¿á½ºÏ‚ Ï€Î±á¿–Î´Î±Ï‚', ' having sent forth he put to death all the boys')]})]\n",
                        "[]\n",
                        "[]\n"
                    ]
                }
            ],
            "source": [
                "for item in d:\n",
                "    print(item)\n",
                "    print(item)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = d[0]\n",
                "blanks = d[1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Î´ÏÎ¿\n",
                        "á¼±Î¼Î¬Ï„Î¹ÏŒÎ½\n",
                        "Ï‡Î¹Ï„á¿¶Î½Î±\n",
                        "Î»Î¬Î²á¿ƒ\n",
                        "Î¿á½Î´á½²\n",
                        "Î Î±Î½Ï„á½¶\n"
                    ]
                }
            ],
            "source": [
                "for item in data:\n",
                "    print(item[1])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Î´ÏÎ¿\n",
                        "á¼±Î¼Î¬Ï„Î¹ÏŒÎ½\n",
                        "Ï‡Î¹Ï„á¿¶Î½Î±\n",
                        "Î»Î¬Î²á¿ƒ\n",
                        "Î¿á½Î´á½²\n",
                        "Î Î±Î½Ï„á½¶\n"
                    ]
                }
            ],
            "source": [
                "produce_material(\"didache\", data, blanks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['Î¼ÎµÏ„', \"'\", 'Î±á½Ï„Î¿á¿¦', '<b>Î´ÏÎ¿</b>', ';', 'á¼á½°Î½', 'á¼„Ïá¿ƒ', 'Ï„Î¹Ï‚', 'Ï„á½¸', 'á¼±Î¼Î¬Ï„Î¹ÏŒÎ½', 'ÏƒÎ¿Ï…', ',', 'Î´á½¸Ï‚', 'Î±á½'] <b>Î´ÏÎ¿</b>\n",
                        "['Î¼ÎµÏ„', \"'\", 'Î±á½Ï„Î¿á¿¦', 'Î´ÏÎ¿', ';', 'á¼á½°Î½', 'á¼„Ïá¿ƒ', 'Ï„Î¹Ï‚', 'Ï„á½¸', '<b>á¼±Î¼Î¬Ï„Î¹ÏŒÎ½</b>', 'ÏƒÎ¿Ï…', ',', 'Î´á½¸Ï‚', 'Î±á½Ï„á¿·', 'ÎºÎ±á½¶', 'Ï„á½¸Î½', 'Ï‡Î¹Ï„á¿¶Î½Î±', ';', 'á¼á½°Î½'] <b>á¼±Î¼Î¬Ï„Î¹ÏŒÎ½</b>\n",
                        "['Ï‚', 'Ï„á½¸', 'á¼±Î¼Î¬Ï„Î¹ÏŒÎ½', 'ÏƒÎ¿Ï…', ',', 'Î´á½¸Ï‚', 'Î±á½Ï„á¿·', 'ÎºÎ±á½¶', 'Ï„á½¸Î½', '<b>Ï‡Î¹Ï„á¿¶Î½Î±</b>', ';', 'á¼á½°Î½', 'Î»Î¬Î²á¿ƒ', 'Ï„Î¹Ï‚', 'á¼€Ï€á½¸', 'ÏƒÎ¿á¿¦', 'Ï„á½¸', 'ÏƒÏŒÎ½', ',', 'Î¼á½´'] <b>Ï‡Î¹Ï„á¿¶Î½Î±</b>\n",
                        "['ÏƒÎ¿Ï…', ',', 'Î´á½¸Ï‚', 'Î±á½Ï„á¿·', 'ÎºÎ±á½¶', 'Ï„á½¸Î½', 'Ï‡Î¹Ï„á¿¶Î½Î±', ';', 'á¼á½°Î½', '<b>Î»Î¬Î²á¿ƒ</b>', 'Ï„Î¹Ï‚', 'á¼€Ï€á½¸', 'ÏƒÎ¿á¿¦', 'Ï„á½¸', 'ÏƒÏŒÎ½', ',', 'Î¼á½´', 'á¼€Ï€Î±Î¯Ï„ÎµÎ¹', ';', 'Î¿á½'] <b>Î»Î¬Î²á¿ƒ</b>\n",
                        "['Î²á¿ƒ', 'Ï„Î¹Ï‚', 'á¼€Ï€á½¸', 'ÏƒÎ¿á¿¦', 'Ï„á½¸', 'ÏƒÏŒÎ½', ',', 'Î¼á½´', 'á¼€Ï€Î±Î¯Ï„ÎµÎ¹', ';', '<b>Î¿á½Î´á½²</b>', 'Î³á½°Ï', 'Î´ÏÎ½Î±ÏƒÎ±Î¹', '.', 'Î Î±Î½Ï„á½¶', 'Ï„á¿·', 'Î±á¼°Ï„Î¿á¿¦Î½Ï„Î¯', 'ÏƒÎµ', 'Î´'] <b>Î¿á½Î´á½²</b>\n",
                        "['ÏŒÎ½', ',', 'Î¼á½´', 'á¼€Ï€Î±Î¯Ï„ÎµÎ¹', ';', 'Î¿á½Î´á½²', 'Î³á½°Ï', 'Î´ÏÎ½Î±ÏƒÎ±Î¹', '.', '<b>Î Î±Î½Ï„á½¶</b>', 'Ï„á¿·', 'Î±á¼°Ï„Î¿á¿¦Î½Ï„Î¯', 'ÏƒÎµ', 'Î´Î¯Î´Î¿Ï…', 'ÎºÎ±á½¶', 'Î¼á½´', 'á¼€Ï€Î±Î¯Ï„ÎµÎ¹'] <b>Î Î±Î½Ï„á½¶</b>\n"
                    ]
                }
            ],
            "source": [
                "for item in data:\n",
                "    c = wf.concordance_list(cltk_normalize(item[1]))\n",
                "    line, bold = boldify_selected_word(cltk_normalize(item[1]), c[0][6])\n",
                "    print(line, bold)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
        },
        "kernelspec": {
            "display_name": "Python 3.7.3 64-bit",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.3"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
