{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER TODO-LIST em README.md\n",
    "from tools.reverso_tools import fetch_element_as_string, get_word_data\n",
    "from reverso_context_api import Client\n",
    "import json, re, string, random, time\n",
    "import urllib.request\n",
    "import spacy, nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATION_NUMBER = 3\n",
    "EXAMPLE_NUMBER = TRANSLATION_NUMBER\n",
    "INPUT_LANGUAGE = \"de\", \"Deutsch\"\n",
    "OUTPUT_LANGUAGE = \"en\", \"English\"\n",
    "client = Client(INPUT_LANGUAGE[0], OUTPUT_LANGUAGE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(file):\n",
    "    f = open(file, \"r\", encoding=\"utf-8\")\n",
    "    text = f.read()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    reworked_text = nltk.Text(tokens)\n",
    "\n",
    "    return text, reworked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_dep_news_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, wf = get_text(\"textos/creative.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [token.lemma_ for token in doc if not token.is_punct]\n",
    "tokens = [token for token in doc if not token.is_punct]\n",
    "pairs = list(set(zip(tokens, lemmas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ways to perfect this function:\n",
    "# check whether the first word in the concordance example is it\n",
    "# if not, cut off this word (so as to remove incomplete words)\n",
    "# do the same to the last word of the sentence\n",
    "\n",
    "def boldify_selected_word(word, string):\n",
    "    string_l = string.split()\n",
    "    for index in range(len(string_l)):\n",
    "        if string_l[index].lower() == word.lower():\n",
    "            bold = \"<b>\"+word.lower()+\"</b>\"\n",
    "            string_l[index] = bold \n",
    "    return string_l, bold\n",
    "\n",
    "def get_context_and_clean_up(word, concordance):\n",
    "\n",
    "    # get word context from concordance\n",
    "    c = concordance.concordance_list((word))\n",
    "\n",
    "    # split string and make chosen word bold\n",
    "    line, bold_word = boldify_selected_word((word), c[0][6])\n",
    "    word_list = line\n",
    "\n",
    "    # remove first and last words of string, as they are sometimes incomplete\n",
    "    # and assert that the first and last \n",
    "    if word_list[0] not in (word, bold_word):\n",
    "        del word_list[0]\n",
    "        if word_list[0] in string.punctuation:\n",
    "            del word_list[0] \n",
    "    if word_list[len(word_list) - 1] not in (word, bold_word):\n",
    "        del word_list[len(word_list) - 1]\n",
    "\n",
    "    # get string with extra spaces\n",
    "    unfinished_string = \" \".join(word_list)\n",
    "    \n",
    "    # remove unnecessary spaces from string\n",
    "    trailing_spaces_start = r\"^\\s+\"\n",
    "    trailing_spaces_end = r\"\\s+$\"\n",
    "\n",
    "    cleaned_up_pre = re.sub(r'\\s([?.!,:;\"](?:\\s|$))', r'\\1', unfinished_string)\n",
    "    cleaned_up_start = re.sub(trailing_spaces_start, \"\", cleaned_up_pre)\n",
    "    final_string = re.sub(trailing_spaces_end, \"\", cleaned_up_start)\n",
    "    \n",
    "    return final_string\n",
    "\n",
    "def clean_up(string):\n",
    "    trailing_spaces_start = r\"^\\s+\"\n",
    "    trailing_spaces_end = r\"\\s+$\"\n",
    "\n",
    "    cleaned_up_pre = re.sub(r'([?.!,:;\"](?:\\s|$))', \"\", string.split()[0])\n",
    "    cleaned_up_start = re.sub(trailing_spaces_start, \"\", cleaned_up_pre)\n",
    "    cleaned_up = re.sub(trailing_spaces_end, \"\", cleaned_up_start)\n",
    "\n",
    "    return cleaned_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_material = []\n",
    "for pair in pairs:\n",
    "    pre_material.append((get_word_data(pair[1], 3, 3), get_context_and_clean_up(pair[0].text, wf)))\n",
    "    print(pair[0].text)\n",
    "    for i in range(0,5):\n",
    "        time.sleep(1)\n",
    "    time.sleep(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "for i in range(len(c)-1):\n",
    "    if c[i][0] != False:\n",
    "        final_list.append(c[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(final_list) - 1):\n",
    "    data = final_list[i][0]\n",
    "    context = final_list[i][1]\n",
    "    md = {\n",
    "        \"name\":fetch_element_as_string(data,\"name\"),\n",
    "        \"translations\": fetch_element_as_string(data,\"translations\"),\n",
    "        \"german\": fetch_element_as_string(data, \"input phrases\"),\n",
    "        \"english\": fetch_element_as_string(data, \"output phrases\"),\n",
    "        \"context\": context\n",
    "    }\n",
    "    dataframe = pd.DataFrame.from_dict(md, orient=\"index\")\n",
    "    dataframe = dataframe.transpose()\n",
    "    dataframe.to_csv(\"german_output.csv\", mode=\"a\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
