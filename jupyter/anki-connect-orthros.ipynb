{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  /usr/bin/python3 -m pip <command> [options]\n",
      "\n",
      "Commands:\n",
      "  install                     Install packages.\n",
      "  download                    Download packages.\n",
      "  uninstall                   Uninstall packages.\n",
      "  freeze                      Output installed packages in requirements format.\n",
      "  list                        List installed packages.\n",
      "  show                        Show information about installed packages.\n",
      "  check                       Verify installed packages have compatible dependencies.\n",
      "  config                      Manage local and global configuration.\n",
      "  search                      Search PyPI for packages.\n",
      "  cache                       Inspect and manage pip's wheel cache.\n",
      "  wheel                       Build wheels from your requirements.\n",
      "  hash                        Compute hashes of package archives.\n",
      "  completion                  A helper command used for command completion.\n",
      "  debug                       Show information useful for debugging.\n",
      "  help                        Show help for commands.\n",
      "\n",
      "General Options:\n",
      "  -h, --help                  Show help.\n",
      "  --isolated                  Run pip in an isolated mode, ignoring\n",
      "                              environment variables and user configuration.\n",
      "  -v, --verbose               Give more output. Option is additive, and can be\n",
      "                              used up to 3 times.\n",
      "  -V, --version               Show version and exit.\n",
      "  -q, --quiet                 Give less output. Option is additive, and can be\n",
      "                              used up to 3 times (corresponding to WARNING,\n",
      "                              ERROR, and CRITICAL logging levels).\n",
      "  --log <path>                Path to a verbose appending log.\n",
      "  --no-input                  Disable prompting for input.\n",
      "  --proxy <proxy>             Specify a proxy in the form\n",
      "                              [user:passwd@]proxy.server:port.\n",
      "  --retries <retries>         Maximum number of retries each connection should\n",
      "                              attempt (default 5 times).\n",
      "  --timeout <sec>             Set the socket timeout (default 15 seconds).\n",
      "  --exists-action <action>    Default action when a path already exists:\n",
      "                              (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort.\n",
      "  --trusted-host <hostname>   Mark this host or host:port pair as trusted,\n",
      "                              even though it does not have valid or any HTTPS.\n",
      "  --cert <path>               Path to alternate CA bundle.\n",
      "  --client-cert <path>        Path to SSL client certificate, a single file\n",
      "                              containing the private key and the certificate\n",
      "                              in PEM format.\n",
      "  --cache-dir <dir>           Store the cache data in <dir>.\n",
      "  --no-cache-dir              Disable the cache.\n",
      "  --disable-pip-version-check\n",
      "                              Don't periodically check PyPI to determine\n",
      "                              whether a new version of pip is available for\n",
      "                              download. Implied with --no-index.\n",
      "  --no-color                  Suppress colored output.\n",
      "  --no-python-version-warning\n",
      "                              Silence deprecation warnings for upcoming\n",
      "                              unsupported Pythons.\n",
      "  --use-feature <feature>     Enable new functionality, that may be backward\n",
      "                              incompatible.\n",
      "  --use-deprecated <feature>  Enable deprecated functionality, that will be\n",
      "                              removed in the future.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER TODO-LIST em README.md\n",
    "import pandas as pd\n",
    "import json, time, urllib.request\n",
    "from tools.tokenization import (get_examples, get_frequency,\n",
    "                    get_text, get_tokens)\n",
    "from requests.exceptions import MissingSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk import NLP\n",
    "from cltk.lemmatize.grc import GreekBackoffLemmatizer\n",
    "lemmatizer = GreekBackoffLemmatizer()\n",
    "\n",
    "from cltk.alphabet.text_normalization import cltk_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.wordstruct import Word as WikWord\n",
    "from tools.scraper import Word as BibleWord\n",
    "from tools.scraper import get_link, get_entry_soup, get_word_data, fetch_group_as_string\n",
    "from tools.scraper import BASE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# ways to perfect this function:\n",
    "# check whether the first word in the concordance example is it\n",
    "# if not, cut off this word (so as to remove incomplete words)\n",
    "# do the same to the last word of the sentence\n",
    "def get_context_example(word, concordance):\n",
    "    \"\"\"\n",
    "    for the purpose of getting an example of the word in question\n",
    "    being used in context, and cleaning up this example \n",
    "    (because NLTK adds a lot of trailing spaces and separates words\n",
    "    from punctuation signals in the string itself)\n",
    "    \"\"\"\n",
    "    trailing_spaces_start = r\"^\\s+\"\n",
    "    trailing_spaces_end = r\"\\s+$\"\n",
    "\n",
    "    context = concordance.concordance_list(word.split()[0])[0][6]\n",
    "    cleaned_up_pre = re.sub(r'\\s([?.!,:;\"](?:\\s|$))', r'\\1', context)\n",
    "    cleaned_up_start = re.sub(trailing_spaces_start, \"\", cleaned_up_pre)\n",
    "    cleaned_up = re.sub(trailing_spaces_end, \"\", cleaned_up_start)\n",
    "\n",
    "    return cleaned_up\n",
    "\n",
    "def clean_up(string):\n",
    "    trailing_spaces_start = r\"^\\s+\"\n",
    "    trailing_spaces_end = r\"\\s+$\"\n",
    "\n",
    "    cleaned_up_pre = re.sub(r'([?.!,:;\"](?:\\s|$))', \"\", string.split()[0])\n",
    "    cleaned_up_start = re.sub(trailing_spaces_start, \"\", cleaned_up_pre)\n",
    "    cleaned_up = re.sub(trailing_spaces_end, \"\", cleaned_up_start)\n",
    "\n",
    "    return cleaned_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€ğ¤€ CLTK version '1.0.23'.\n",
      "Pipeline for language 'Ancient Greek' (ISO: 'grc'): `GreekNormalizeProcess`, `GreekStanzaProcess`, `GreekEmbeddingsProcess`, `StopsProcess`, `GreekNERProcess`.\n"
     ]
    }
   ],
   "source": [
    "orthros, wf = get_text(\"textos/orthros.txt\")\n",
    "tokens, token_set, phrases = get_tokens(orthros)\n",
    "frequency = get_frequency(tokens)\n",
    "cltk_nlp = NLP(language=\"grc\")\n",
    "cltk_doc = cltk_nlp.analyze(orthros)\n",
    "\n",
    "wordlist = []\n",
    "for pair in frequency:\n",
    "    token = pair[0]\n",
    "    wordlist.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(action, **params):\n",
    "    return {'action': action,\n",
    "            'params': params,\n",
    "            'version': 6}\n",
    "\n",
    "def invoke(action, **params):\n",
    "    requestJson = json.dumps(request(action, **params)).encode('utf-8')\n",
    "    response = json.load(urllib.request.urlopen(urllib.request.Request('http://localhost:8765', requestJson)))\n",
    "\n",
    "    if len(response) != 2:\n",
    "        raise Exception('response has an unexpected number of fields')\n",
    "\n",
    "    if 'error' not in response:\n",
    "        raise Exception('response is missing required error field')\n",
    "    \n",
    "    if 'result' not in response:\n",
    "        raise Exception('response is missing required result field')\n",
    "\n",
    "    if response['error'] is not None:\n",
    "        raise Exception(response['error'])\n",
    "\n",
    "    return response['result']\n",
    "\n",
    "noteIDs1 = invoke('findNotes', query='deck:Î•Î»Î»Î·Î½Î¹ÎºÎ¬::Liturgia')\n",
    "noteIDs2 = invoke('findNotes', query='deck:Î•Î»Î»Î·Î½Î¹ÎºÎ¬::Credo')\n",
    "noteIDs = noteIDs1 + noteIDs2\n",
    "notesInfo = invoke('notesInfo', notes=noteIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "for card in notesInfo:\n",
    "    notes.append(cltk_normalize(clean_up(card['fields']['Word']['value'])))\n",
    "fwl = [cltk_normalize(word) for word in wordlist if word not in notes]\n",
    "notes_group = lemmatizer.lemmatize(notes)\n",
    "fwl_group = lemmatizer.lemmatize(fwl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_lemmas = set([tuple[1] for tuple in notes_group])\n",
    "fwl_lemmas = set([tuple[1] for tuple in fwl_group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_fwl_lemmas = [word for word in fwl_lemmas if word not in notes_lemmas]\n",
    "reworked_fwl = [tuple for tuple in fwl_group if tuple[1] in filtered_fwl_lemmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# antes Ã© necessÃ¡rio fazer com que as palavras idÃªnticas aos seus \n",
    "# lemas nÃ£o provoquem redundÃ¢ncia, desfazendo as tuplas\n",
    "# em uma string Ãºnica\n",
    "\n",
    "for i in range(len(reworked_fwl)):\n",
    "#    for j in reworked_fwl[i]:\n",
    "    if reworked_fwl[i][0] == reworked_fwl[i][1]:\n",
    "        reworked_fwl[i] = reworked_fwl[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_bible_word(word):\n",
    "    link = get_link(BASE_URL, word)\n",
    "    soup = get_entry_soup(link)\n",
    "    word = BibleWord(get_word_data(soup))\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isso pode ser aperfeiÃ§oado para tornar mais legÃ­vel\n",
    "# em vez de usar uma n-tupla no return value, usar\n",
    "# um dicionÃ¡rio\n",
    "\n",
    "def searcher(word):\n",
    "\n",
    "    if type(word) == tuple:\n",
    "        try:\n",
    "            bible_word = fetch_bible_word(word[0])\n",
    "            return {\"search_num\": 1, \"source\": \"BibleHub\", \"input\": word[0], \"output\": bible_word.data}\n",
    "\n",
    "        except MissingSchema:\n",
    "            try:\n",
    "                bible_word = fetch_bible_word(word[1])\n",
    "                return {\"search_num\": 2, \"source\": \"BibleHub\", \"input\": word[0], \"output\": bible_word.data}\n",
    "\n",
    "            except MissingSchema:\n",
    "\n",
    "                return {\"search_num\": 2, \"source\": None, \"input\": word[0], \"output\": None}\n",
    "                \n",
    "\n",
    "    elif type(word) == str:\n",
    "        try: \n",
    "            bible_word = fetch_bible_word(word)\n",
    "            return {\"search_num\": 1, \"source\": \"BibleHub\", \"input\": word, \"output\": bible_word.data}\n",
    "\n",
    "        except:\n",
    "                return {\"search_num\": 1, \"source\": None, \"input\": word, \"output\": None}\n",
    "\n",
    "    else:\n",
    "\n",
    "        return {\"search_num\": 0, \"source\": None, \"input\": word, \"output\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word no. 1: Î§ÏÎ¹ÏƒÏ„á½¸Ï‚\n",
      "word no. 2: ('Î¸Î±Î½Î¬Ï„á¿³', 'Î¸Î¬Î½Î±Ï„Î¿Ï‚')\n",
      "word no. 3: ('Î¸Î¬Î½Î±Ï„Î¿Î½', 'Î¸Î¬Î½Î±Ï„Î¿Ï‚')\n",
      "word no. 4: ('Ï€Î±Ï„Î®ÏƒÎ±Ï‚', 'Ï€Î±Ï„Î­Ï‰')\n",
      "word no. 5: ('Î¼Î½Î®Î¼Î±ÏƒÎ¹', 'Î¼Î½Î·Í‚Î¼Î±')\n",
      "word no. 6: ('Ï‡Î±ÏÎ¹ÏƒÎ¬Î¼ÎµÎ½Î¿Ï‚', 'Ï‡Î±ÏÎ¯Î¶Î¿Î¼Î±Î¹')\n",
      "word no. 7: ('!', 'punc')\n"
     ]
    }
   ],
   "source": [
    "# Ã‰ necessÃ¡rio criar alguma forma de verificar se\n",
    "# as palavras que o script adquiriu correspondem Ã s palavras\n",
    "# do input, uma vez que as palavras obtidas do BibleHub podem ser,\n",
    "# devido ao meu algoritmo meio porco, nÃ£o muito confiÃ¡veis\n",
    "\n",
    "# uma ideia interessante seria adicionar um marcador ao lado, algo como \n",
    "\n",
    "# Mais uma coisa a aperfeiÃ§oar:\n",
    "# Se a mesma palavra jÃ¡ estiver presente, deixar de lado\n",
    "# nÃ£o o mesmo radical, mas *a mesma palavra*\n",
    "\n",
    "def acquire_data(list):\n",
    "\n",
    "    bible_searches = 0\n",
    "    wiki_searches = 0\n",
    "    data = []\n",
    "    blanks = []\n",
    "    already_present = []\n",
    "\n",
    "    for index in range(len(list)):\n",
    "        print(\"word no. {}: {}\".format(index+1, list[index]))\n",
    "        word_dict = searcher(list[index])\n",
    "\n",
    "        if a[1] != False:\n",
    "            result = (word_dict[\"source\"], word_dict[\"input\"], word_dict[\"output\"])\n",
    "            if result[2] not in already_present:\n",
    "                data.append(result)\n",
    "            already_present.append(result[2])\n",
    "        else:\n",
    "            blanks.append(word_dict[\"input\"])\n",
    "\n",
    "        bible_searches += word_dict[\"search_num\"]\n",
    "\n",
    "        if bible_searches >= 10:\n",
    "            for n in range(60):\n",
    "                time.sleep(1)\n",
    "                print(\"Wait... {}/60\".format(n))\n",
    "                bible_searches = 0\n",
    "    \n",
    "    return data, blanks\n",
    "\n",
    "data, blanks = acquire_data(reworked_fwl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î§ÏÎ¹ÏƒÏ„á½¸Ï‚\n",
      "Î¸Î±Î½Î¬Ï„á¿³\n",
      "Î¸Î¬Î½Î±Ï„Î¿Î½\n",
      "Ï€Î±Ï„Î®ÏƒÎ±Ï‚\n",
      "Î¼Î½Î®Î¼Î±ÏƒÎ¹\n",
      "Ï‡Î±ÏÎ¹ÏƒÎ¬Î¼ÎµÎ½Î¿Ï‚\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for item in data:\n",
    "    if item[0] == \"BibleHub\":\n",
    "\n",
    "        print(item[1])\n",
    "\n",
    "        curr = item[2]\n",
    "        concordances = curr[\"concordances\"]\n",
    "\n",
    "        dc = {\n",
    "            \"word\": concordances[\"Original Word\"],\n",
    "            \"phonetics\": concordances[\"Phonetic Spelling\"],\n",
    "            \"category\": concordances[\"Part of Speech\"],\n",
    "            \"meaning\": concordances['Definition'],\n",
    "            \"greek\": fetch_group_as_string([tuple[0] for tuple in curr['examples']], single_list=True),\n",
    "            \"english\": fetch_group_as_string([tuple[1] for tuple in curr['examples']], single_list=True),\n",
    "        }\n",
    "\n",
    "        dc[\"context\"] = get_context_example(item[1], wf)\n",
    "        \n",
    "        # to display which word is being worked upon at the time\n",
    "\n",
    "        words_dataframe = pd.DataFrame.from_dict(dc, orient=\"index\")\n",
    "        words_dataframe = words_dataframe.transpose()\n",
    "        words_dataframe.to_csv(\"anesti_output.csv\", encoding=\"utf-8\", mode=\"a\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-e654d8f28ff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcurr_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concordances'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Original Word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconcordance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcordance_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcleaned_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\s([?.!,:;\"](?:\\s|$))'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\\1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcordance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"^\\s+\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "curr_d = data[0][1]\n",
    "word_name = curr_d['concordances']['Original Word']\n",
    "concordance = wf.concordance_list(word_name)[0][6]\n",
    "cleaned_up = re.sub(r'\\s([?.!,:;\"](?:\\s|$))', r'\\1', concordance)\n",
    "pattern = r\"^\\s+\"\n",
    "cleaned_up = re.sub(pattern,\"\",cleaned_up)\n",
    "cleaned_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€ğ¤€ CLTK version '1.0.23'.\n",
      "Pipeline for language 'Ancient Greek' (ISO: 'grc'): `GreekNormalizeProcess`, `GreekStanzaProcess`, `GreekEmbeddingsProcess`, `StopsProcess`, `GreekNERProcess`.\n"
     ]
    }
   ],
   "source": [
    "anesti, wf = get_text(\"textos/anesti.txt\")\n",
    "tokens, token_set, phrases = get_tokens(anesti)\n",
    "frequency = get_frequency(tokens)\n",
    "cltk_nlp = NLP(language=\"grc\")\n",
    "cltk_doc = cltk_nlp.analyze(anesti)\n",
    "\n",
    "wordlist = []\n",
    "for pair in frequency:\n",
    "    token = pair[0]\n",
    "    wordlist.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BibleHub',\n",
       "  'Î§ÏÎ¹ÏƒÏ„á½¸Ï‚',\n",
       "  {'concordances': {'Original Word': 'Î§ÏÎ¹ÏƒÏ„ÏŒÏ‚, Î¿á¿¦, á½',\n",
       "    'Part of Speech': 'Noun, Masculine',\n",
       "    'Transliteration': 'Christos',\n",
       "    'Phonetic Spelling': \"(khris-tos')\",\n",
       "    'Definition': 'the Anointed One, Messiah, Christ',\n",
       "    'Usage': 'Anointed One; the Messiah, the Christ.'},\n",
       "   'examples': [('á½ Î»ÎµÎ³ÏŒÎ¼ÎµÎ½Î¿Ï‚ Î§ÏÎ¹ÏƒÏ„ÏŒÏ‚ ', ' who is called Christ'),\n",
       "    ('á¼•Ï‰Ï‚ Ï„Î¿á¿¦ Ï‡ÏÎ¹ÏƒÏ„Î¿á¿¦ Î³ÎµÎ½ÎµÎ±á½¶ Î´ÎµÎºÎ±Ï„Î­ÏƒÏƒÎ±ÏÎµÏ‚',\n",
       "     ' to the Christ generations fourteen'),\n",
       "    ('Î”Î• Î™Î—Î£ÎŸÎ¥ Î§Î¡Î™Î£Î¤ÎŸÎ¥ á¼¡ Î³Î­Î½ÎµÏƒÎ¹Ï‚', ' now of Jesus Christ the birth')]}),\n",
       " ('BibleHub',\n",
       "  'Î¸Î±Î½Î¬Ï„á¿³',\n",
       "  {'concordances': {'Original Word': 'Î¸Î¬Î½Î±Ï„Î¿Ï‚, Î¿Ï…, á½',\n",
       "    'Part of Speech': 'Noun, Masculine',\n",
       "    'Transliteration': 'thanatos',\n",
       "    'Phonetic Spelling': \"(than'-at-os)\",\n",
       "    'Definition': 'death',\n",
       "    'Usage': 'death, physical or spiritual.'},\n",
       "   'examples': [('á¼€Î´ÎµÎ»Ï†á½¸Î½ Îµá¼°Ï‚ Î¸Î¬Î½Î±Ï„Î¿Î½ ÎºÎ±á½¶ Ï€Î±Ï„á½´Ï',\n",
       "     ' brother to death and father'),\n",
       "    ('á¼¢ Î¼Î·Ï„Î­ÏÎ± Î¸Î±Î½Î¬Ï„á¿³ Ï„ÎµÎ»ÎµÏ…Ï„Î¬Ï„Ï‰ ', ' or mother in death must die'),\n",
       "    ('Î¼á½´ Î³ÎµÏÏƒÏ‰Î½Ï„Î±Î¹ Î¸Î±Î½Î¬Ï„Î¿Ï… á¼•Ï‰Ï‚ á¼‚Î½',\n",
       "     ' not shall taste of death until anyhow')]}),\n",
       " ('BibleHub',\n",
       "  'Ï€Î±Ï„Î®ÏƒÎ±Ï‚',\n",
       "  {'concordances': {'Original Word': 'Ï€Î±Ï„Î­Ï‰',\n",
       "    'Part of Speech': 'Verb',\n",
       "    'Transliteration': 'pateÃ³',\n",
       "    'Phonetic Spelling': \"(pat-eh'-o)\",\n",
       "    'Definition': 'to tread or tread on',\n",
       "    'Usage': 'I tread, trample upon.'},\n",
       "   'examples': [('á¼¸ÎµÏÎ¿Ï…ÏƒÎ±Î»á½´Î¼ á¼”ÏƒÏ„Î±Î¹ Ï€Î±Ï„Î¿Ï…Î¼Î­Î½Î· á½‘Ï€á½¸ á¼Î¸Î½á¿¶Î½',\n",
       "     ' Jersualem will be trodden down by [the] Gentiles'),\n",
       "    ('Ï„á½´Î½ á¼Î³Î¯Î±Î½ Ï€Î±Ï„Î®ÏƒÎ¿Ï…ÏƒÎ¹Î½ Î¼á¿†Î½Î±Ï‚ Ï„ÎµÏƒÏƒÎµÏÎ¬ÎºÎ¿Î½Ï„Î±',\n",
       "     ' holy will they trample upon months forty'),\n",
       "    ('ÎºÎ±á½¶ á¼Ï€Î±Ï„Î®Î¸Î· á¼¡ Î»Î·Î½á½¸Ï‚', ' and was trodden the winepress')]}),\n",
       " ('BibleHub',\n",
       "  'Î¼Î½Î®Î¼Î±ÏƒÎ¹',\n",
       "  {'concordances': {'Original Word': 'Î¼Î½á¿†Î¼Î±, Î±Ï„Î¿Ï‚, Ï„ÏŒ',\n",
       "    'Part of Speech': 'Noun, Neuter',\n",
       "    'Transliteration': 'mnÃ©ma',\n",
       "    'Phonetic Spelling': \"(mnay'-mah)\",\n",
       "    'Definition': 'a memorial, a sepulcher',\n",
       "    'Usage': 'a tomb, monument, memorial.'},\n",
       "   'examples': [('á¼Î½ Ï„Î¿á¿–Ï‚ Î¼Î½Î®Î¼Î±ÏƒÎ¹Î½ ÎºÎ±á½¶ á¼Î½', ' in the tombs and in'),\n",
       "    ('á¼Î½ Ï„Î¿á¿–Ï‚ Î¼Î½Î®Î¼Î±ÏƒÎ¹Î½ ', ' in the tombs'),\n",
       "    ('Î±á½Ï„á½¸Î½ á¼Î½ Î¼Î½Î®Î¼Î±Ï„Î¹ Î»Î±Î¾ÎµÏ…Ï„á¿· Î¿á½—', ' it in a tomb cut in a rock in which')]}),\n",
       " ('BibleHub',\n",
       "  'Ï‡Î±ÏÎ¹ÏƒÎ¬Î¼ÎµÎ½Î¿Ï‚',\n",
       "  {'concordances': {'Original Word': 'Ï‡Î±ÏÎ¯Î¶Î¿Î¼Î±Î¹',\n",
       "    'Part of Speech': 'Verb',\n",
       "    'Transliteration': 'charizomai',\n",
       "    'Phonetic Spelling': \"(khar-id'-zom-ahee)\",\n",
       "    'Definition': 'to show favor, give freely',\n",
       "    'Usage': '(a) I show favor to, (b) I pardon, forgive, (c) I show kindness.'},\n",
       "   'examples': [('á¼€Ï€Î¿Î´Î¿á¿¦Î½Î±Î¹ á¼€Î¼Ï†Î¿Ï„Î­ÏÎ¿Î¹Ï‚ á¼Ï‡Î±ÏÎ¯ÏƒÎ±Ï„Î¿ Ï„Î¯Ï‚ Î¿á½–Î½',\n",
       "     ' to pay both he forgave which therefore'),\n",
       "    ('Ï„á½¸ Ï€Î»Îµá¿–Î¿Î½ á¼Ï‡Î±ÏÎ¯ÏƒÎ±Ï„Î¿ á½ Î´á½²', ' the most he forgave And'),\n",
       "    ('á¼„Î½Î´ÏÎ± Ï†Î¿Î½Î­Î± Ï‡Î±ÏÎ¹ÏƒÎ¸á¿†Î½Î±Î¹ á½‘Î¼á¿–Î½ ',\n",
       "     ' a man a murderer to be granted to you')]}),\n",
       " (None, '!', None)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noteIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punc',\n",
       " 'Î§ÏÎ¹ÏƒÏ„á½¸Ï‚',\n",
       " 'Î¶Ï‰Î®',\n",
       " 'Î¸Î¬Î½Î±Ï„Î¿Ï‚',\n",
       " 'Î¼Î½Î·Í‚Î¼Î±',\n",
       " 'Î½ÎµÎºÏÏŒÏ‚',\n",
       " 'Ï€Î±Ï„Î­Ï‰',\n",
       " 'Ï‡Î±ÏÎ¯Î¶Î¿Î¼Î±Î¹',\n",
       " 'á¼€Î½Î¯ÏƒÏ„Î·Î¼Î¹',\n",
       " 'á¼Îº'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwl_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Î”ÏŒÎ¾Î±',\n",
       " 'Î•á½Î»Î¿Î³Î·Ï„á½¸Ï‚',\n",
       " 'Î˜ÎµÏŒÏ‚',\n",
       " 'Î˜Îµá½¸Î½',\n",
       " 'ÎšÏÏÎ¹Îµ',\n",
       " 'ÎœÎ±ÏÎ¯Î±',\n",
       " 'Î Î±Ï„ÏÏŒÏ‚',\n",
       " 'Î Î¹Î»á¾¶Ï„Î¿Ï‚',\n",
       " 'Î ÏÎ¿ÏƒÎ´Î¿Îºá¿¶',\n",
       " 'Î ÏŒÎ½Ï„Î¹Î¿Ï‚',\n",
       " 'Î£Ï„Î±Ï…ÏÏ‰Î¸Î­Î½Ï„Î±',\n",
       " 'Î§ÏÎ¹ÏƒÏ„ÏŒÏ‚',\n",
       " 'Î±á¼°Î½Î­Ï‰',\n",
       " 'Î±á¼°ÏÎ½',\n",
       " 'Î±á¼´Î½ÎµÏƒÎ¹Ï‚',\n",
       " 'Î²Î¬Ï€Ï„Î¹ÏƒÎ¼Î±',\n",
       " 'Î²Î±ÏƒÎ¯Î»ÎµÎ¹Î¿Ï‚',\n",
       " 'Î³Î¯Î³Î½Î¿Î¼Î±Î¹',\n",
       " 'Î³ÎµÎ½ÎµÎ¬',\n",
       " 'Î³ÎµÎ½Î½Î¬Ï‰',\n",
       " 'Î³Î¹Î³Î½ÏÏƒÎºÏ‰',\n",
       " 'Î³ÏÎ±Ï†Î®',\n",
       " 'Î³á¿†',\n",
       " 'Î´Î­Î·ÏƒÎ¹Ï‚',\n",
       " 'Î´Î¯Î´Î±Î¾ÏŒÎ½',\n",
       " 'Î´Î¯Î´Ï‰Î¼Î¹',\n",
       " 'Î´ÎµÎ¯ÎºÎ½Ï…Î¼Î¹',\n",
       " 'Î´ÎµÎ¾Î¹ÏŒÏ‚',\n",
       " 'Î´Î¹Î¬',\n",
       " 'Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î¬',\n",
       " 'Î´Î¹â€™',\n",
       " 'Î´Î¿Î¾Î¬Î¶Ï‰',\n",
       " 'Î´ÏŒÎ¾Î±',\n",
       " 'Î´ÏÎ½Î±Î¼Î¹Ï‚',\n",
       " 'Îµá¼°Î¼Î¯',\n",
       " 'Îµá¼°ÏÎ®Î½Î·',\n",
       " 'Îµá¼°Ï‚',\n",
       " 'Îµá¼°ÏƒÏ†Î­ÏÏ‰',\n",
       " 'Îµá¼¶Î¼Î¹',\n",
       " 'Îµá¼·Ï‚',\n",
       " 'Îµá½Î´Î¿ÎºÎ¯Î±',\n",
       " 'Îµá½Î»Î¿Î³Î­Ï‰',\n",
       " 'Îµá½Î»Î¿Î³Î¯Î±',\n",
       " 'Îµá½Ï‡Î±ÏÎ¹ÏƒÏ„Î­Ï‰',\n",
       " 'Î¶Î¬Ï‰',\n",
       " 'Î¶Ï‰Î®',\n",
       " 'Î¶Ï‰Î¿Ï€Î¿Î¹ÏŒÏ‚',\n",
       " 'Î¸Î¬Ï€Ï„Ï‰',\n",
       " 'Î¸Î­Î»Î·Î¼Î¬',\n",
       " 'Î¸ÎµÏŒÏ‚',\n",
       " 'ÎºÎ¬Î¸Î·Î¼Î±Î¹',\n",
       " 'ÎºÎ±Î¯',\n",
       " 'ÎºÎ±Î¸Î¬',\n",
       " 'ÎºÎ±Î¸Î¿Î»Î¹Îºá½´Î½',\n",
       " 'ÎºÎ±Ï„Î¬',\n",
       " 'ÎºÎ±Ï„Î¬Î½Ï…Î¾Î¹Ï‚',\n",
       " 'ÎºÎ±Ï„Î¬á¼•Î¶Î¿Î¼Î±Î¹',\n",
       " 'ÎºÎ±Ï„Î­ÏÏ‡Î¿Î¼Î±Î¹',\n",
       " 'ÎºÎ±Ï„Î±Ï†ÎµÏÎ³Ï‰',\n",
       " 'ÎºÏÎ¯Î½Ï‰',\n",
       " 'ÎºÏŒÏƒÎ¼Î¿Ï‚',\n",
       " 'ÎºÏÏÎ¹Î¿Ï‚',\n",
       " 'Î»Î­Î³Ï‰',\n",
       " 'Î»Î±Î»Î­Ï‰',\n",
       " 'Î¼Î­Î³Î±Ï‚',\n",
       " 'Î¼Î­Î»Î»Ï‰',\n",
       " 'Î¼Î®',\n",
       " 'Î¼Î®Ï„Î·Ï',\n",
       " 'Î¼Î±ÎºÎ±ÏÎ¯Î¶Ï‰',\n",
       " 'Î¼ÎµÎ³Î±Î»ÏÎ½Ï‰',\n",
       " 'Î¼ÎµÏ„Î¬',\n",
       " 'Î¼Î¿Î½Î¿Î³ÎµÎ½Î®Ï‚',\n",
       " 'Î¼ÏŒÎ½Î¿Ï‚',\n",
       " 'Î½ÎµÎºÏÏŒÏ‚',\n",
       " 'Î½á¿¦Î½',\n",
       " 'Î¿á½',\n",
       " 'Î¿á½ÏÎ±Î½ÏŒÏ‚',\n",
       " 'Î¿á½—Ï„Î¿Ï‚',\n",
       " 'Ï€Î¬Î»Î¹Î½',\n",
       " 'Ï€Î¬ÏƒÏ‡Ï‰',\n",
       " 'Ï€Î±Î½Î±Î¼ÏÎ¼Î·Ï„Î¿Î½',\n",
       " 'Ï€Î±Î½Ï„Î¿ÎºÏÎ¬Ï„Ï‰Ï',\n",
       " 'Ï€Î±ÏÎ¬',\n",
       " 'Ï€Î±ÏÎ±Ï„ÎµÎ¯Î½Ï‰',\n",
       " 'Ï€Î±ÏÎ¸Î­Î½Î¿Ï‚',\n",
       " 'Ï€Î±Ï„Î®Ï',\n",
       " 'Ï€ÎµÎ¹ÏÎ±ÏƒÎ¼ÏŒÏ‚',\n",
       " 'Ï€Î·Î³Î®',\n",
       " 'Ï€Î¹ÏƒÏ„ÎµÏÏ‰',\n",
       " 'Ï€Î½Îµá¿¦Î¼Î±',\n",
       " 'Ï€Î¿Î¹Î­Ï‰',\n",
       " 'Ï€Î¿Î¹Î·Ï„Î®Ï‚',\n",
       " 'Ï€Î¿Î½Î·ÏÏŒÏ‚',\n",
       " 'Ï€ÏÎ¿ÏƒÎµÏÏ‡Î¿Î¼Î±Î¹',\n",
       " 'Ï€ÏÎ¿ÏƒÎºÏ…Î½Î­Ï‰',\n",
       " 'Ï€ÏÎ¿Ï†Î®Ï„Î·Ï‚',\n",
       " 'Ï€ÏÏŒ',\n",
       " 'Ï€ÏÏŒÏ‚',\n",
       " 'Ï€á¾¶Ï‚',\n",
       " 'ÏƒÎ®Î¼ÎµÏÎ¿Î½',\n",
       " 'ÏƒÎ±ÏÎºÏŒÏ‰',\n",
       " 'ÏƒÏ…Î½Î´Î¿Î¾Î¬Î¶Ï‰',\n",
       " 'ÏƒÏ‰Ï„Î®Ï',\n",
       " 'ÏƒÏ‰Ï„Î·ÏÎ¯Î±',\n",
       " 'ÏƒÏ',\n",
       " 'ÏƒÏÎ½',\n",
       " 'Ï„Î­Î»Î¿Ï‚',\n",
       " 'Ï„Î¯ÎºÏ„Ï‰',\n",
       " 'Ï„Î¯Î¼Î¹Î¿Ï‚',\n",
       " 'Ï„Îµ',\n",
       " 'Ï„ÏÎ¯Ï„Î¿Ï‚',\n",
       " 'Ï…á¼±ÏŒÏ‚',\n",
       " 'Ï†Î¬Î¿Ï‚',\n",
       " 'Ï†Ï…Î»Î¬ÏƒÏƒÏ‰',\n",
       " 'Ï†ÏÏ‚',\n",
       " 'ÏˆÏ…Ï‡Î®',\n",
       " 'á¼€Î´Î¹Î¬Ï†Î¸Î¿ÏÎ¿Ï‚',\n",
       " 'á¼€ÎµÎ¯',\n",
       " 'á¼€ÎµÎ¹Î¼Î±ÎºÎ¬ÏÎ¹ÏƒÏ„Î¿Î½',\n",
       " 'á¼€Î¸Î¬Î½Î±Ï„Î¿Ï‚',\n",
       " 'á¼€Î»Î·Î¸Î®Ï‚',\n",
       " 'á¼€Î»Î·Î¸Î¹Î½ÏŒÏ‚',\n",
       " 'á¼€Î»Î»Î¬',\n",
       " 'á¼€Î¼Î½ÏŒÏ‚',\n",
       " 'á¼€Î½Î¬ÏƒÏ„Î±ÏƒÎ¹Ï‚',\n",
       " 'á¼€Î½Î­ÏÏ‡Î¿Î¼Î±Î¹',\n",
       " 'á¼€Î½Î¯ÏƒÏ„Î·Î¼Î¹',\n",
       " 'á¼€Î½Î±Î¼Î¬ÏÏ„Î·Ï„Î¿Ï‚',\n",
       " 'á¼€Ï€Î¿ÏƒÏ„Î¿Î»Î¹Îºá½´Î½',\n",
       " 'á¼€Ï€ÏŒ',\n",
       " 'á¼€ÏƒÏÎ³ÎºÏÎ¹Ï„Î¿Ï‚',\n",
       " 'á¼€Ï†Î¯Î·Î¼Î¹',\n",
       " 'á¼€ÏŒÏÎ±Ï„Î¿Ï‚',\n",
       " 'á¼Î³Î¹Î¬Î¶Ï‰',\n",
       " 'á¼Î¼Î±ÏÏ„Î¬Î½Ï‰',\n",
       " 'á¼Î¼Î±ÏÏ„Î¯Î±',\n",
       " 'á¼Î¼ÏŒÏ‚',\n",
       " 'á¼„Î½Î¸ÏÏ‰Ï€Î¿Ï‚',\n",
       " 'á¼„ÏÏ„Î¿Ï‚',\n",
       " 'á¼„Ï†ÎµÏƒÎ¹Ï‚',\n",
       " 'á¼…Î³Î¹Î¿Ï‚',\n",
       " 'á¼ˆÎ³ÏÎ¯Ï€Ï€Î±Ï‚',\n",
       " 'á¼Î³Î¹Î¿Ï‚',\n",
       " 'á¼Î³Ï',\n",
       " 'á¼Îº',\n",
       " 'á¼ÎºÎºÎ»Î·ÏƒÎ¯Î±',\n",
       " 'á¼ÎºÏ€Î¿ÏÎµÏÏ‰',\n",
       " 'á¼Î»ÎµÎ­Ï‰',\n",
       " 'á¼Î»Ï€Î¯Î¶Ï‰',\n",
       " 'á¼Î½',\n",
       " 'á¼Î½Î±Î½Î¸ÏÏ‰Ï€Î­Ï‰',\n",
       " 'á¼Ï€Î¯',\n",
       " 'á¼Ï€Î¹Î¿ÏÏƒÎ¹Î¿Ï‚',\n",
       " 'á¼Ï€Î¿Ï…ÏÎ¬Î½Î¹Î¿Ï‚',\n",
       " 'á¼”Î»ÎµÏŒÏ‚',\n",
       " 'á¼”Î½Î´Î¿Î¾Î¿Ï‚',\n",
       " 'á¼”ÏÏ‡Î¿Î¼Î±Î¹',\n",
       " 'á¼•ÎºÎ±ÏƒÏ„Î¿Ï‚',\n",
       " 'á¼¡Î¼Î­ÏÎ±',\n",
       " 'á¼¡Î¼Î­Ï„ÎµÏÎ¿Ï‚',\n",
       " 'á¼°Î¬Î¿Î¼Î±Î¹',\n",
       " 'á¼µÎ·Î¼Î¹',\n",
       " 'á¼¸Î·ÏƒÎ¿á¿¦',\n",
       " 'á¼¸Î·ÏƒÎ¿á¿¦Ï‚',\n",
       " 'á¼¸ÏƒÏ‡Ï…ÏÏŒÏ‚',\n",
       " 'á½€Ï†ÎµÎ¯Î»Î·Î¼Î±',\n",
       " 'á½€Ï†ÎµÎ¹Î»Î­Ï„Î·Ï‚',\n",
       " 'á½',\n",
       " 'á½Î¼Î¿Î»Î¿Î³Î­Ï‰',\n",
       " 'á½Î¼Î¿Î¿ÏÏƒÎ¹Î¿Ï‚',\n",
       " 'á½ÏÎ¬Ï‰',\n",
       " 'á½ÏÎ±Ï„ÏŒÏ‚',\n",
       " 'á½„Î½Î¿Î¼Î¬',\n",
       " 'á½„Î½Ï„Ï‰Ï‚',\n",
       " 'á½…Ï„Î¹',\n",
       " 'á½‘Ï€Î­Ï',\n",
       " 'á½•ÏˆÎ¹ÏƒÏ„Î¿Ï‚',\n",
       " 'á½¡Ï‚',\n",
       " 'á¿¥ÏÎ¿Î¼Î±Î¹'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Î½ÎµÎºÏÏŒÏ‚'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_up(notes[188])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ÎºÎ±á½¶',\n",
       " 'á¼Î³Î¹Î¿Ï‚',\n",
       " 'á½',\n",
       " 'ÎšÏÏÎ¹Îµ',\n",
       " 'á¼¡Î¼á¾¶Ï‚',\n",
       " 'ÏƒÎ¿Ï…',\n",
       " 'Ï„Î¿á¿¦',\n",
       " 'á¼Î½',\n",
       " 'Ï„á½¸',\n",
       " 'Îµá¼°Ï‚',\n",
       " 'Îµá¼¶',\n",
       " 'á¼Î»Î­Î·ÏƒÎ¿Î½',\n",
       " 'Î˜ÎµÏŒÏ‚',\n",
       " 'ÏƒÎµ',\n",
       " 'á¼€Î¸Î¬Î½Î±Ï„Î¿Ï‚',\n",
       " 'Î¼Îµ',\n",
       " 'á¼¡Î¼á¿¶Î½',\n",
       " 'á¼¡',\n",
       " 'á¼¸ÏƒÏ‡Ï…ÏÏŒÏ‚',\n",
       " 'Ï„á½°',\n",
       " 'Î´Î¯Î´Î±Î¾ÏŒÎ½',\n",
       " 'Î•á½Î»Î¿Î³Î·Ï„á½¸Ï‚',\n",
       " 'Ï„á½¸Î½',\n",
       " 'Ï„á½´Î½',\n",
       " 'Ï„Î¿á¿–Ï‚',\n",
       " 'á¼¡Î¼á¿–Î½',\n",
       " 'Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î¬',\n",
       " 'Ï„Î¿á½ºÏ‚',\n",
       " 'á½„Î½Î¿Î¼Î¬',\n",
       " 'Ïƒá½º',\n",
       " 'Î´á½¸Ï‚',\n",
       " 'Ï„á¿†Ï‚',\n",
       " 'Î½á¿¦Î½',\n",
       " 'Ï†Ï‰Ï„Î¯',\n",
       " 'ÏƒÎ¿á½¶',\n",
       " 'Ï€Î±Ïá½°',\n",
       " 'Ï€Î¿Î¹Îµá¿–Î½',\n",
       " 'Ïƒá½²',\n",
       " 'Ï€Ïá½¸Ï‚',\n",
       " 'ÏˆÏ…Ï‡Î®Î½',\n",
       " 'ÏƒÎ­',\n",
       " 'á¼ Î»Ï€Î¯ÏƒÎ±Î¼ÎµÎ½',\n",
       " 'ÎºÎ±Î¸Î¬Ï€ÎµÏ',\n",
       " 'Ï„Î±ÏÏ„á¿ƒ',\n",
       " 'á¼¡Î¼Î­Ïá¾³',\n",
       " 'Ï„á¿‡',\n",
       " 'Î±á¼°á¿¶Î½Î¿Ï‚',\n",
       " 'á¼¡Î¼Î­ÏÎ±Î½',\n",
       " 'á¼‘ÎºÎ¬ÏƒÏ„Î·Î½',\n",
       " 'á¼¸Î·ÏƒÎ¿á¿¦Ï‚',\n",
       " 'Î´ÎµÎ¾Î¹á¾·',\n",
       " 'Ï„á½°Ï‚',\n",
       " 'á¼¸Î·ÏƒÎ¿á¿¦',\n",
       " 'Î¼ÎµÎ³Î¬Î»Î·Î½',\n",
       " 'Î´Î¹á½°',\n",
       " 'á¼€Î½Î¸ÏÏÏ€Î¿Î¹Ï‚',\n",
       " 'Îµá¼°ÏÎ®Î½Î·',\n",
       " 'Î³á¿†Ï‚',\n",
       " 'á½‘ÏˆÎ¯ÏƒÏ„Î¿Î¹Ï‚',\n",
       " 'á½Ï„Î¹',\n",
       " 'Î Î±Ï„ÏÏŒÏ‚',\n",
       " 'á¼Ï€á½¶',\n",
       " 'Î”ÏŒÎ¾Î±',\n",
       " 'á½¡Ï‚',\n",
       " 'Î²Î±ÏƒÎ¹Î»ÎµÎ¯Î±',\n",
       " 'Î¸Î­Î»Î·Î¼Î¬',\n",
       " 'á½…Ï„Î¹',\n",
       " 'Î¼Î¿Ï…',\n",
       " 'á¼”Î»ÎµÏŒÏ‚',\n",
       " 'Ï„á¿¶Î½',\n",
       " 'Î¼ÏŒÎ½Î¿Ï‚',\n",
       " 'ÎºÏŒÏƒÎ¼Î¿Ï…',\n",
       " 'Î´ÏŒÎ¾Î±Î½',\n",
       " 'ÏƒÎ¿Î¹',\n",
       " 'Ï†á¿¶Ï‚',\n",
       " 'Ï„á¿·',\n",
       " 'á¼€Î¼Î®Î½',\n",
       " 'Î´ÏŒÎ¾Î±',\n",
       " 'Î´ÏÎ½Î±Î¼Î¹Ï‚',\n",
       " 'á¼ÏƒÏ„Î¹Î½',\n",
       " 'ÏƒÎ¿á¿¦',\n",
       " 'á¼€Ï€á½¸',\n",
       " 'á¼€Î»Î»á½°',\n",
       " 'á¼¡Î¼Îµá¿–Ï‚',\n",
       " 'Î³ÎµÎ½Îµá¾·',\n",
       " 'Ï€Î¿Î½Î·ÏÎ¿á¿¦',\n",
       " 'á¿¥á¿¦ÏƒÎ±Î¹',\n",
       " 'Ï€ÎµÎ¹ÏÎ±ÏƒÎ¼ÏŒÎ½',\n",
       " 'Îµá¼°ÏƒÎµÎ½Î­Î³Îºá¿ƒÏ‚',\n",
       " 'Î¼á½´',\n",
       " 'ÏƒÏ‰Ï„Î®Ï',\n",
       " 'á½€Ï†ÎµÎ¹Î»Î­Ï„Î·Ï‚',\n",
       " 'á¼€Ï†Î¯Î·Î¼Î¹',\n",
       " 'á½€Ï†ÎµÎ¯Î»Î·Î¼Î±',\n",
       " 'ÏƒÎ®Î¼ÎµÏÎ¿Î½',\n",
       " 'Îµá½Ï‡Î±ÏÎ¹ÏƒÏ„Î­Ï‰',\n",
       " 'Î´Î¿Î¾Î¬Î¶Ï‰',\n",
       " 'Ï€ÏÎ¿ÏƒÎºÏ…Î½Î­Ï‰',\n",
       " 'Îµá½Î»Î¿Î³Î¯Î±',\n",
       " 'Îµá½Î´Î¿ÎºÎ¯Î±',\n",
       " 'ÏƒÏ',\n",
       " 'Î´ÎµÎ¯ÎºÎ½Ï…Î¼Î¹',\n",
       " 'Î¼Î¿Î½Î¿Î³ÎµÎ½Î®Ï‚',\n",
       " 'á¼Î»ÎµÎ­Ï‰',\n",
       " 'Ï€Î±Î½Ï„Î¿ÎºÏÎ¬Ï„Ï‰Ï',\n",
       " 'Î¸ÎµÏŒÏ‚',\n",
       " 'á¼Ï€Î¿Ï…ÏÎ¬Î½Î¹Î¿Ï‚',\n",
       " 'á¼ˆÎ³ÏÎ¯Ï€Ï€Î±Ï‚',\n",
       " 'á¼Î¼Î±ÏÏ„Î¯Î±',\n",
       " 'Ï…á¼±ÏŒÏ‚',\n",
       " 'á¼€Î¼Î½ÏŒÏ‚',\n",
       " 'Ï€Î½Îµá¿¦Î¼Î±',\n",
       " 'Î§ÏÎ¹ÏƒÏ„ÏŒÏ‚',\n",
       " 'ÎºÎ¬Î¸Î·Î¼Î±Î¹',\n",
       " 'Î´Î­Î·ÏƒÎ¹Ï‚',\n",
       " 'Ï€ÏÎ¿ÏƒÎµÏÏ‡Î¿Î¼Î±Î¹',\n",
       " 'Î±á¼´Î½ÎµÏƒÎ¹Ï‚',\n",
       " 'Îµá½Î»Î¿Î³Î­Ï‰',\n",
       " 'ÎºÎ±Ï„Î¬',\n",
       " 'ÎºÏÏÎ¹Î¿Ï‚',\n",
       " 'ÎºÎ±Ï„Î¬Î½Ï…Î¾Î¹Ï‚',\n",
       " 'Ï†Ï…Î»Î¬ÏƒÏƒÏ‰',\n",
       " 'á¼€Î½Î±Î¼Î¬ÏÏ„Î·Ï„Î¿Ï‚',\n",
       " 'á¼Ï€Î¯',\n",
       " 'Î³Î¯Î½Î¿Î¼Î±Î¹',\n",
       " 'Î±á¼°Î½Î­Ï‰',\n",
       " 'Ï€Î±Ï„Î®Ï',\n",
       " 'á¼°Î¬Î¿Î¼Î±Î¹',\n",
       " 'Î»Î­Î³Ï‰',\n",
       " 'á¼Î³Ï',\n",
       " 'á¼Î¼Î±ÏÏ„Î¬Î½Ï‰',\n",
       " 'ÎºÎ±Ï„Î±Ï†ÎµÏÎ³Ï‰',\n",
       " 'Î¶Ï‰Î®',\n",
       " 'Ï€Î·Î³Î®',\n",
       " 'Î³Î¹Î½ÏÏƒÎºÏ‰',\n",
       " 'Ï€Î±ÏÎ±Ï„ÎµÎ¯Î½Ï‰',\n",
       " 'á½ÏÎ¬Ï‰',\n",
       " 'Î±á¼°ÏÎ½',\n",
       " 'á¼€ÎµÎ¯',\n",
       " 'á¼”ÏÏ‡Î¿Î¼Î±Î¹',\n",
       " 'á¼Î³Î¹Î¬Î¶Ï‰',\n",
       " 'Î¿á½ÏÎ±Î½ÏŒÏ‚',\n",
       " 'á¼Ï€Î¹Î¿ÏÏƒÎ¹Î¿Ï‚',\n",
       " 'á¼„ÏÏ„Î¿Ï‚',\n",
       " 'á¼€Î»Î·Î¸á¿¶Ï‚',\n",
       " 'Î¼Î±ÎºÎ±ÏÎ¯Î¶ÎµÎ¹Î½',\n",
       " 'á¼€ÎµÎ¹Î¼Î±ÎºÎ¬ÏÎ¹ÏƒÏ„Î¿Î½',\n",
       " 'Ï€Î±Î½Î±Î¼ÏÎ¼Î·Ï„Î¿Î½',\n",
       " 'Î¼Î·Ï„Î­ÏÎ±',\n",
       " 'Ï„Î¹Î¼Î¹Ï‰Ï„Î­ÏÎ±Î½',\n",
       " 'á¼€ÏƒÏ…Î³ÎºÏÎ¯Ï„Ï‰Ï‚',\n",
       " 'á¼Î½Î´Î¿Î¾Î¿Ï„Î­ÏÎ±Î½',\n",
       " 'á¼€Î´Î¹Î±Ï†Î¸ÏŒÏÏ‰Ï‚',\n",
       " 'Î˜Îµá½¸Î½',\n",
       " 'Ï„ÎµÎºÎ¿á¿¦ÏƒÎ±Î½',\n",
       " 'á½„Î½Ï„Ï‰Ï‚',\n",
       " 'Î¼ÎµÎ³Î±Î»ÏÎ½Î¿Î¼ÎµÎ½',\n",
       " 'á¼…Î³Î¹Î¿Ï‚',\n",
       " 'Î´Î¹â€™',\n",
       " 'á¼€Î»Î·Î¸Î¹Î½ÏŒÏ‚',\n",
       " 'á¼€Î¼Î®Î½',\n",
       " 'á¼€Î½Î¬ÏƒÏ„Î±ÏƒÎ¹Ï‚',\n",
       " 'á¼€Î½Î­ÏÏ‡Î¿Î¼Î±Î¹',\n",
       " 'á¼€Î½Î¯ÏƒÏ„Î·Î¼Î¹',\n",
       " 'á¼€ÏŒÏÎ±Ï„Î¿Ï‚',\n",
       " 'á¼„Ï†ÎµÏƒÎ¹Ï‚',\n",
       " 'Î²Î¬Ï€Ï„Î¹ÏƒÎ¼Î±',\n",
       " 'Î²Î±ÏƒÎ¹Î»ÎµÎ¯Î±',\n",
       " 'Î³ÎµÎ½Î½Î¬Ï‰',\n",
       " 'Î³ÏÎ±Ï†Î®',\n",
       " 'Îµá¼°Ï‚',\n",
       " 'Îµá¼·Ï‚',\n",
       " 'á¼Îº',\n",
       " 'á¼ÎºÎºÎ»Î·ÏƒÎ¯Î±',\n",
       " 'á¼ÎºÏ€Î¿ÏÎµÏÎ¿Î¼Î±Î¹',\n",
       " 'Î¶Î¬Ï‰',\n",
       " 'á¼¡Î¼Î­Ï„ÎµÏÎ¿Ï‚',\n",
       " 'Î¸Î¬Ï€Ï„Ï‰',\n",
       " 'Î¸ÎµÏŒÏ‚',\n",
       " 'á¼¸Î·ÏƒÎ¿á¿¦Ï‚',\n",
       " 'ÎºÎ±Î¸Î­Î¶Î¿Î¼Î±Î¹',\n",
       " 'ÎºÎ±Ï„Î­ÏÏ‡Î¿Î¼Î±Î¹',\n",
       " 'ÎºÏÎ¯Î½Ï‰',\n",
       " 'ÎºÏÏÎ¹Î¿Ï‚',\n",
       " 'Î»Î±Î»Î­Ï‰',\n",
       " 'ÎœÎ±ÏÎ¯Î±',\n",
       " 'Î¼Î­Î»Î»Ï‰',\n",
       " 'Î¼ÎµÏ„Î¬',\n",
       " 'Î½ÎµÎºÏÏŒÏ‚',\n",
       " 'á½Î¼Î¿Î»Î¿Î³Î­Ï‰',\n",
       " 'á½Î¼Î¿Î¿ÏÏƒÎ¹Î¿Ï‚',\n",
       " 'á½ÏÎ±Ï„ÏŒÏ‚',\n",
       " 'Î¿á½',\n",
       " 'Î¿á½—',\n",
       " 'Î¿á½ÏÎ±Î½ÏŒÏ‚',\n",
       " 'Ï€Î¬Î»Î¹Î½',\n",
       " 'Ï€Î±ÏÎ¸Î­Î½Î¿Ï‚',\n",
       " 'Ï€á¾¶Ï‚',\n",
       " 'Ï€Î¬ÏƒÏ‡Ï‰',\n",
       " 'Ï€Î±Ï„Î®Ï',\n",
       " 'Î Î¹Î»á¾¶Ï„Î¿Ï‚',\n",
       " 'Ï€Î¹ÏƒÏ„ÎµÏÏ‰',\n",
       " 'Ï€Î½Îµá¿¦Î¼Î±',\n",
       " 'Ï€Î¿Î¹Î·Ï„Î®Ï‚',\n",
       " 'Î ÏŒÎ½Ï„Î¹Î¿Ï‚',\n",
       " 'Ï€ÏÏŒ',\n",
       " 'Ï€ÏÎ¿Ï†Î®Ï„Î·Ï‚',\n",
       " 'ÏƒÏÎ½',\n",
       " 'ÏƒÏ…Î½Î´Î¿Î¾Î¬Î¶Ï‰',\n",
       " 'ÏƒÏ‰Ï„Î·ÏÎ¯Î±',\n",
       " 'Ï„Î­',\n",
       " 'Ï„Î­Î»Î¿Ï‚',\n",
       " 'Ï„ÏÎ¯Ï„Î¿Ï‚',\n",
       " 'Ï…á¼±ÏŒÏ‚',\n",
       " 'á½‘Ï€Î­Ï',\n",
       " 'Ï†á¿¶Ï‚',\n",
       " 'Î§ÏÎ¹ÏƒÏ„ÏŒÏ‚',\n",
       " 'á¼Î½Î±Î½Î¸ÏÏ‰Ï€Î®ÏƒÎ±Î½Ï„Î±',\n",
       " 'Î£Ï„Î±Ï…ÏÏ‰Î¸Î­Î½Ï„Î±',\n",
       " 'Î¶Ï‰Î¿Ï€Î¿Î¹ÏŒÎ½',\n",
       " 'ÎºÎ±Î¸Î¿Î»Î¹Îºá½´Î½',\n",
       " 'á¼€Ï€Î¿ÏƒÏ„Î¿Î»Î¹Îºá½´Î½',\n",
       " 'Î ÏÎ¿ÏƒÎ´Î¿Îºá¿¶',\n",
       " 'ÏƒÎ±ÏÎºÏ‰Î¸Î­Î½Ï„Î±']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [(1,2,3), 4, 5, (6,7,8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
