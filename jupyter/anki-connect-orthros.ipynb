{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  /usr/bin/python3 -m pip <command> [options]\n",
      "\n",
      "Commands:\n",
      "  install                     Install packages.\n",
      "  download                    Download packages.\n",
      "  uninstall                   Uninstall packages.\n",
      "  freeze                      Output installed packages in requirements format.\n",
      "  list                        List installed packages.\n",
      "  show                        Show information about installed packages.\n",
      "  check                       Verify installed packages have compatible dependencies.\n",
      "  config                      Manage local and global configuration.\n",
      "  search                      Search PyPI for packages.\n",
      "  cache                       Inspect and manage pip's wheel cache.\n",
      "  wheel                       Build wheels from your requirements.\n",
      "  hash                        Compute hashes of package archives.\n",
      "  completion                  A helper command used for command completion.\n",
      "  debug                       Show information useful for debugging.\n",
      "  help                        Show help for commands.\n",
      "\n",
      "General Options:\n",
      "  -h, --help                  Show help.\n",
      "  --isolated                  Run pip in an isolated mode, ignoring\n",
      "                              environment variables and user configuration.\n",
      "  -v, --verbose               Give more output. Option is additive, and can be\n",
      "                              used up to 3 times.\n",
      "  -V, --version               Show version and exit.\n",
      "  -q, --quiet                 Give less output. Option is additive, and can be\n",
      "                              used up to 3 times (corresponding to WARNING,\n",
      "                              ERROR, and CRITICAL logging levels).\n",
      "  --log <path>                Path to a verbose appending log.\n",
      "  --no-input                  Disable prompting for input.\n",
      "  --proxy <proxy>             Specify a proxy in the form\n",
      "                              [user:passwd@]proxy.server:port.\n",
      "  --retries <retries>         Maximum number of retries each connection should\n",
      "                              attempt (default 5 times).\n",
      "  --timeout <sec>             Set the socket timeout (default 15 seconds).\n",
      "  --exists-action <action>    Default action when a path already exists:\n",
      "                              (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort.\n",
      "  --trusted-host <hostname>   Mark this host or host:port pair as trusted,\n",
      "                              even though it does not have valid or any HTTPS.\n",
      "  --cert <path>               Path to alternate CA bundle.\n",
      "  --client-cert <path>        Path to SSL client certificate, a single file\n",
      "                              containing the private key and the certificate\n",
      "                              in PEM format.\n",
      "  --cache-dir <dir>           Store the cache data in <dir>.\n",
      "  --no-cache-dir              Disable the cache.\n",
      "  --disable-pip-version-check\n",
      "                              Don't periodically check PyPI to determine\n",
      "                              whether a new version of pip is available for\n",
      "                              download. Implied with --no-index.\n",
      "  --no-color                  Suppress colored output.\n",
      "  --no-python-version-warning\n",
      "                              Silence deprecation warnings for upcoming\n",
      "                              unsupported Pythons.\n",
      "  --use-feature <feature>     Enable new functionality, that may be backward\n",
      "                              incompatible.\n",
      "  --use-deprecated <feature>  Enable deprecated functionality, that will be\n",
      "                              removed in the future.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER TODO-LIST em README.md\n",
    "import pandas as pd\n",
    "import json, time, urllib.request\n",
    "from tools.tokenization import (get_examples, get_frequency,\n",
    "                    get_text, get_tokens)\n",
    "from requests.exceptions import MissingSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk import NLP\n",
    "from cltk.lemmatize.grc import GreekBackoffLemmatizer\n",
    "lemmatizer = GreekBackoffLemmatizer()\n",
    "\n",
    "from cltk.alphabet.text_normalization import cltk_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.wordstruct import Word as WikWord\n",
    "from tools.scraper import Word as BibleWord\n",
    "from tools.scraper import get_link, get_entry_soup, get_word_data, fetch_group_as_string\n",
    "from tools.scraper import BASE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# ways to perfect this function:\n",
    "# check whether the first word in the concordance example is it\n",
    "# if not, cut off this word (so as to remove incomplete words)\n",
    "# do the same to the last word of the sentence\n",
    "def get_context_example(word, concordance):\n",
    "    \"\"\"\n",
    "    for the purpose of getting an example of the word in question\n",
    "    being used in context, and cleaning up this example \n",
    "    (because NLTK adds a lot of trailing spaces and separates words\n",
    "    from punctuation signals in the string itself)\n",
    "    \"\"\"\n",
    "    trailing_spaces_start = r\"^\\s+\"\n",
    "    trailing_spaces_end = r\"\\s+$\"\n",
    "\n",
    "    context = concordance.concordance_list(word.split()[0])[0][6]\n",
    "    cleaned_up_pre = re.sub(r'\\s([?.!,:;\"](?:\\s|$))', r'\\1', context)\n",
    "    cleaned_up_start = re.sub(trailing_spaces_start, \"\", cleaned_up_pre)\n",
    "    cleaned_up = re.sub(trailing_spaces_end, \"\", cleaned_up_start)\n",
    "\n",
    "    return cleaned_up\n",
    "\n",
    "def clean_up(string):\n",
    "    trailing_spaces_start = r\"^\\s+\"\n",
    "    trailing_spaces_end = r\"\\s+$\"\n",
    "\n",
    "    cleaned_up_pre = re.sub(r'([?.!,:;\"](?:\\s|$))', \"\", string.split()[0])\n",
    "    cleaned_up_start = re.sub(trailing_spaces_start, \"\", cleaned_up_pre)\n",
    "    cleaned_up = re.sub(trailing_spaces_end, \"\", cleaned_up_start)\n",
    "\n",
    "    return cleaned_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äéê§Ä CLTK version '1.0.23'.\n",
      "Pipeline for language 'Ancient Greek' (ISO: 'grc'): `GreekNormalizeProcess`, `GreekStanzaProcess`, `GreekEmbeddingsProcess`, `StopsProcess`, `GreekNERProcess`.\n"
     ]
    }
   ],
   "source": [
    "orthros, wf = get_text(\"textos/orthros.txt\")\n",
    "tokens, token_set, phrases = get_tokens(orthros)\n",
    "frequency = get_frequency(tokens)\n",
    "cltk_nlp = NLP(language=\"grc\")\n",
    "cltk_doc = cltk_nlp.analyze(orthros)\n",
    "\n",
    "wordlist = []\n",
    "for pair in frequency:\n",
    "    token = pair[0]\n",
    "    wordlist.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(action, **params):\n",
    "    return {'action': action,\n",
    "            'params': params,\n",
    "            'version': 6}\n",
    "\n",
    "def invoke(action, **params):\n",
    "    requestJson = json.dumps(request(action, **params)).encode('utf-8')\n",
    "    response = json.load(urllib.request.urlopen(urllib.request.Request('http://localhost:8765', requestJson)))\n",
    "\n",
    "    if len(response) != 2:\n",
    "        raise Exception('response has an unexpected number of fields')\n",
    "\n",
    "    if 'error' not in response:\n",
    "        raise Exception('response is missing required error field')\n",
    "    \n",
    "    if 'result' not in response:\n",
    "        raise Exception('response is missing required result field')\n",
    "\n",
    "    if response['error'] is not None:\n",
    "        raise Exception(response['error'])\n",
    "\n",
    "    return response['result']\n",
    "\n",
    "noteIDs1 = invoke('findNotes', query='deck:ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨::Liturgia')\n",
    "noteIDs2 = invoke('findNotes', query='deck:ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨::Credo')\n",
    "noteIDs = noteIDs1 + noteIDs2\n",
    "notesInfo = invoke('notesInfo', notes=noteIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "for card in notesInfo:\n",
    "    notes.append(cltk_normalize(clean_up(card['fields']['Word']['value'])))\n",
    "fwl = [cltk_normalize(word) for word in wordlist if word not in notes]\n",
    "notes_group = lemmatizer.lemmatize(notes)\n",
    "fwl_group = lemmatizer.lemmatize(fwl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_lemmas = set([tuple[1] for tuple in notes_group])\n",
    "fwl_lemmas = set([tuple[1] for tuple in fwl_group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_fwl_lemmas = [word for word in fwl_lemmas if word not in notes_lemmas]\n",
    "reworked_fwl = [tuple for tuple in fwl_group if tuple[1] in filtered_fwl_lemmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# antes √© necess√°rio fazer com que as palavras id√™nticas aos seus \n",
    "# lemas n√£o provoquem redund√¢ncia, desfazendo as tuplas\n",
    "# em uma string √∫nica\n",
    "\n",
    "for i in range(len(reworked_fwl)):\n",
    "#    for j in reworked_fwl[i]:\n",
    "    if reworked_fwl[i][0] == reworked_fwl[i][1]:\n",
    "        reworked_fwl[i] = reworked_fwl[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_bible_word(word):\n",
    "    link = get_link(BASE_URL, word)\n",
    "    soup = get_entry_soup(link)\n",
    "    word = BibleWord(get_word_data(soup))\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isso pode ser aperfei√ßoado para tornar mais leg√≠vel\n",
    "# em vez de usar uma n-tupla no return value, usar\n",
    "# um dicion√°rio\n",
    "\n",
    "def searcher(word):\n",
    "\n",
    "    if type(word) == tuple:\n",
    "        try:\n",
    "            bible_word = fetch_bible_word(word[0])\n",
    "            return {\"search_num\": 1, \"source\": \"BibleHub\", \"input\": word[0], \"output\": bible_word.data}\n",
    "\n",
    "        except MissingSchema:\n",
    "            try:\n",
    "                bible_word = fetch_bible_word(word[1])\n",
    "                return {\"search_num\": 2, \"source\": \"BibleHub\", \"input\": word[0], \"output\": bible_word.data}\n",
    "\n",
    "            except MissingSchema:\n",
    "\n",
    "                return {\"search_num\": 2, \"source\": None, \"input\": word[0], \"output\": None}\n",
    "                \n",
    "\n",
    "    elif type(word) == str:\n",
    "        try: \n",
    "            bible_word = fetch_bible_word(word)\n",
    "            return {\"search_num\": 1, \"source\": \"BibleHub\", \"input\": word, \"output\": bible_word.data}\n",
    "\n",
    "        except:\n",
    "                return {\"search_num\": 1, \"source\": None, \"input\": word, \"output\": None}\n",
    "\n",
    "    else:\n",
    "\n",
    "        return {\"search_num\": 0, \"source\": None, \"input\": word, \"output\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word no. 1: ŒßœÅŒπœÉœÑ·Ω∏œÇ\n",
      "word no. 2: ('Œ∏Œ±ŒΩŒ¨œÑ·ø≥', 'Œ∏Œ¨ŒΩŒ±œÑŒøœÇ')\n",
      "word no. 3: ('Œ∏Œ¨ŒΩŒ±œÑŒøŒΩ', 'Œ∏Œ¨ŒΩŒ±œÑŒøœÇ')\n",
      "word no. 4: ('œÄŒ±œÑŒÆœÉŒ±œÇ', 'œÄŒ±œÑŒ≠œâ')\n",
      "word no. 5: ('ŒºŒΩŒÆŒºŒ±œÉŒπ', 'ŒºŒΩŒ∑ÕÇŒºŒ±')\n",
      "word no. 6: ('œáŒ±œÅŒπœÉŒ¨ŒºŒµŒΩŒøœÇ', 'œáŒ±œÅŒØŒ∂ŒøŒºŒ±Œπ')\n",
      "word no. 7: ('!', 'punc')\n"
     ]
    }
   ],
   "source": [
    "# √â necess√°rio criar alguma forma de verificar se\n",
    "# as palavras que o script adquiriu correspondem √†s palavras\n",
    "# do input, uma vez que as palavras obtidas do BibleHub podem ser,\n",
    "# devido ao meu algoritmo meio porco, n√£o muito confi√°veis\n",
    "\n",
    "# uma ideia interessante seria adicionar um marcador ao lado, algo como \n",
    "\n",
    "# Mais uma coisa a aperfei√ßoar:\n",
    "# Se a mesma palavra j√° estiver presente, deixar de lado\n",
    "# n√£o o mesmo radical, mas *a mesma palavra*\n",
    "\n",
    "def acquire_data(list):\n",
    "\n",
    "    bible_searches = 0\n",
    "    wiki_searches = 0\n",
    "    data = []\n",
    "    blanks = []\n",
    "    already_present = []\n",
    "\n",
    "    for index in range(len(list)):\n",
    "        print(\"word no. {}: {}\".format(index+1, list[index]))\n",
    "        word_dict = searcher(list[index])\n",
    "\n",
    "        if a[1] != False:\n",
    "            result = (word_dict[\"source\"], word_dict[\"input\"], word_dict[\"output\"])\n",
    "            if result[2] not in already_present:\n",
    "                data.append(result)\n",
    "            already_present.append(result[2])\n",
    "        else:\n",
    "            blanks.append(word_dict[\"input\"])\n",
    "\n",
    "        bible_searches += word_dict[\"search_num\"]\n",
    "\n",
    "        if bible_searches >= 10:\n",
    "            for n in range(60):\n",
    "                time.sleep(1)\n",
    "                print(\"Wait... {}/60\".format(n))\n",
    "                bible_searches = 0\n",
    "    \n",
    "    return data, blanks\n",
    "\n",
    "data, blanks = acquire_data(reworked_fwl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ŒßœÅŒπœÉœÑ·Ω∏œÇ\n",
      "Œ∏Œ±ŒΩŒ¨œÑ·ø≥\n",
      "Œ∏Œ¨ŒΩŒ±œÑŒøŒΩ\n",
      "œÄŒ±œÑŒÆœÉŒ±œÇ\n",
      "ŒºŒΩŒÆŒºŒ±œÉŒπ\n",
      "œáŒ±œÅŒπœÉŒ¨ŒºŒµŒΩŒøœÇ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for item in data:\n",
    "    if item[0] == \"BibleHub\":\n",
    "\n",
    "        print(item[1])\n",
    "\n",
    "        curr = item[2]\n",
    "        concordances = curr[\"concordances\"]\n",
    "\n",
    "        dc = {\n",
    "            \"word\": concordances[\"Original Word\"],\n",
    "            \"phonetics\": concordances[\"Phonetic Spelling\"],\n",
    "            \"category\": concordances[\"Part of Speech\"],\n",
    "            \"meaning\": concordances['Definition'],\n",
    "            \"greek\": fetch_group_as_string([tuple[0] for tuple in curr['examples']], single_list=True),\n",
    "            \"english\": fetch_group_as_string([tuple[1] for tuple in curr['examples']], single_list=True),\n",
    "        }\n",
    "\n",
    "        dc[\"context\"] = get_context_example(item[1], wf)\n",
    "        \n",
    "        # to display which word is being worked upon at the time\n",
    "\n",
    "        words_dataframe = pd.DataFrame.from_dict(dc, orient=\"index\")\n",
    "        words_dataframe = words_dataframe.transpose()\n",
    "        words_dataframe.to_csv(\"anesti_output.csv\", encoding=\"utf-8\", mode=\"a\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-e654d8f28ff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcurr_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concordances'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Original Word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconcordance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcordance_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcleaned_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\s([?.!,:;\"](?:\\s|$))'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\\1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcordance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"^\\s+\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "curr_d = data[0][1]\n",
    "word_name = curr_d['concordances']['Original Word']\n",
    "concordance = wf.concordance_list(word_name)[0][6]\n",
    "cleaned_up = re.sub(r'\\s([?.!,:;\"](?:\\s|$))', r'\\1', concordance)\n",
    "pattern = r\"^\\s+\"\n",
    "cleaned_up = re.sub(pattern,\"\",cleaned_up)\n",
    "cleaned_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äéê§Ä CLTK version '1.0.23'.\n",
      "Pipeline for language 'Ancient Greek' (ISO: 'grc'): `GreekNormalizeProcess`, `GreekStanzaProcess`, `GreekEmbeddingsProcess`, `StopsProcess`, `GreekNERProcess`.\n"
     ]
    }
   ],
   "source": [
    "anesti, wf = get_text(\"textos/anesti.txt\")\n",
    "tokens, token_set, phrases = get_tokens(anesti)\n",
    "frequency = get_frequency(tokens)\n",
    "cltk_nlp = NLP(language=\"grc\")\n",
    "cltk_doc = cltk_nlp.analyze(anesti)\n",
    "\n",
    "wordlist = []\n",
    "for pair in frequency:\n",
    "    token = pair[0]\n",
    "    wordlist.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BibleHub',\n",
       "  'ŒßœÅŒπœÉœÑ·Ω∏œÇ',\n",
       "  {'concordances': {'Original Word': 'ŒßœÅŒπœÉœÑœåœÇ, Œø·ø¶, ·ΩÅ',\n",
       "    'Part of Speech': 'Noun, Masculine',\n",
       "    'Transliteration': 'Christos',\n",
       "    'Phonetic Spelling': \"(khris-tos')\",\n",
       "    'Definition': 'the Anointed One, Messiah, Christ',\n",
       "    'Usage': 'Anointed One; the Messiah, the Christ.'},\n",
       "   'examples': [('·ΩÅ ŒªŒµŒ≥œåŒºŒµŒΩŒøœÇ ŒßœÅŒπœÉœÑœåœÇ ', ' who is called Christ'),\n",
       "    ('·ºïœâœÇ œÑŒø·ø¶ œáœÅŒπœÉœÑŒø·ø¶ Œ≥ŒµŒΩŒµŒ±·Ω∂ Œ¥ŒµŒ∫Œ±œÑŒ≠œÉœÉŒ±œÅŒµœÇ',\n",
       "     ' to the Christ generations fourteen'),\n",
       "    ('ŒîŒï ŒôŒóŒ£ŒüŒ• ŒßŒ°ŒôŒ£Œ§ŒüŒ• ·º° Œ≥Œ≠ŒΩŒµœÉŒπœÇ', ' now of Jesus Christ the birth')]}),\n",
       " ('BibleHub',\n",
       "  'Œ∏Œ±ŒΩŒ¨œÑ·ø≥',\n",
       "  {'concordances': {'Original Word': 'Œ∏Œ¨ŒΩŒ±œÑŒøœÇ, ŒøœÖ, ·ΩÅ',\n",
       "    'Part of Speech': 'Noun, Masculine',\n",
       "    'Transliteration': 'thanatos',\n",
       "    'Phonetic Spelling': \"(than'-at-os)\",\n",
       "    'Definition': 'death',\n",
       "    'Usage': 'death, physical or spiritual.'},\n",
       "   'examples': [('·ºÄŒ¥ŒµŒªœÜ·Ω∏ŒΩ Œµ·º∞œÇ Œ∏Œ¨ŒΩŒ±œÑŒøŒΩ Œ∫Œ±·Ω∂ œÄŒ±œÑ·Ω¥œÅ',\n",
       "     ' brother to death and father'),\n",
       "    ('·º¢ ŒºŒ∑œÑŒ≠œÅŒ± Œ∏Œ±ŒΩŒ¨œÑ·ø≥ œÑŒµŒªŒµœÖœÑŒ¨œÑœâ ', ' or mother in death must die'),\n",
       "    ('Œº·Ω¥ Œ≥ŒµœçœÉœâŒΩœÑŒ±Œπ Œ∏Œ±ŒΩŒ¨œÑŒøœÖ ·ºïœâœÇ ·ºÇŒΩ',\n",
       "     ' not shall taste of death until anyhow')]}),\n",
       " ('BibleHub',\n",
       "  'œÄŒ±œÑŒÆœÉŒ±œÇ',\n",
       "  {'concordances': {'Original Word': 'œÄŒ±œÑŒ≠œâ',\n",
       "    'Part of Speech': 'Verb',\n",
       "    'Transliteration': 'pate√≥',\n",
       "    'Phonetic Spelling': \"(pat-eh'-o)\",\n",
       "    'Definition': 'to tread or tread on',\n",
       "    'Usage': 'I tread, trample upon.'},\n",
       "   'examples': [('·º∏ŒµœÅŒøœÖœÉŒ±Œª·Ω¥Œº ·ºîœÉœÑŒ±Œπ œÄŒ±œÑŒøœÖŒºŒ≠ŒΩŒ∑ ·ΩëœÄ·Ω∏ ·ºêŒ∏ŒΩ·ø∂ŒΩ',\n",
       "     ' Jersualem will be trodden down by [the] Gentiles'),\n",
       "    ('œÑ·Ω¥ŒΩ ·ºÅŒ≥ŒØŒ±ŒΩ œÄŒ±œÑŒÆœÉŒøœÖœÉŒπŒΩ Œº·øÜŒΩŒ±œÇ œÑŒµœÉœÉŒµœÅŒ¨Œ∫ŒøŒΩœÑŒ±',\n",
       "     ' holy will they trample upon months forty'),\n",
       "    ('Œ∫Œ±·Ω∂ ·ºêœÄŒ±œÑŒÆŒ∏Œ∑ ·º° ŒªŒ∑ŒΩ·Ω∏œÇ', ' and was trodden the winepress')]}),\n",
       " ('BibleHub',\n",
       "  'ŒºŒΩŒÆŒºŒ±œÉŒπ',\n",
       "  {'concordances': {'Original Word': 'ŒºŒΩ·øÜŒºŒ±, Œ±œÑŒøœÇ, œÑœå',\n",
       "    'Part of Speech': 'Noun, Neuter',\n",
       "    'Transliteration': 'mn√©ma',\n",
       "    'Phonetic Spelling': \"(mnay'-mah)\",\n",
       "    'Definition': 'a memorial, a sepulcher',\n",
       "    'Usage': 'a tomb, monument, memorial.'},\n",
       "   'examples': [('·ºêŒΩ œÑŒø·øñœÇ ŒºŒΩŒÆŒºŒ±œÉŒπŒΩ Œ∫Œ±·Ω∂ ·ºêŒΩ', ' in the tombs and in'),\n",
       "    ('·ºêŒΩ œÑŒø·øñœÇ ŒºŒΩŒÆŒºŒ±œÉŒπŒΩ ', ' in the tombs'),\n",
       "    ('Œ±·ΩêœÑ·Ω∏ŒΩ ·ºêŒΩ ŒºŒΩŒÆŒºŒ±œÑŒπ ŒªŒ±ŒæŒµœÖœÑ·ø∑ Œø·Ωó', ' it in a tomb cut in a rock in which')]}),\n",
       " ('BibleHub',\n",
       "  'œáŒ±œÅŒπœÉŒ¨ŒºŒµŒΩŒøœÇ',\n",
       "  {'concordances': {'Original Word': 'œáŒ±œÅŒØŒ∂ŒøŒºŒ±Œπ',\n",
       "    'Part of Speech': 'Verb',\n",
       "    'Transliteration': 'charizomai',\n",
       "    'Phonetic Spelling': \"(khar-id'-zom-ahee)\",\n",
       "    'Definition': 'to show favor, give freely',\n",
       "    'Usage': '(a) I show favor to, (b) I pardon, forgive, (c) I show kindness.'},\n",
       "   'examples': [('·ºÄœÄŒøŒ¥Œø·ø¶ŒΩŒ±Œπ ·ºÄŒºœÜŒøœÑŒ≠œÅŒøŒπœÇ ·ºêœáŒ±œÅŒØœÉŒ±œÑŒø œÑŒØœÇ Œø·ΩñŒΩ',\n",
       "     ' to pay both he forgave which therefore'),\n",
       "    ('œÑ·Ω∏ œÄŒªŒµ·øñŒøŒΩ ·ºêœáŒ±œÅŒØœÉŒ±œÑŒø ·ΩÅ Œ¥·Ω≤', ' the most he forgave And'),\n",
       "    ('·ºÑŒΩŒ¥œÅŒ± œÜŒøŒΩŒ≠Œ± œáŒ±œÅŒπœÉŒ∏·øÜŒΩŒ±Œπ ·ΩëŒº·øñŒΩ ',\n",
       "     ' a man a murderer to be granted to you')]}),\n",
       " (None, '!', None)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noteIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punc',\n",
       " 'ŒßœÅŒπœÉœÑ·Ω∏œÇ',\n",
       " 'Œ∂œâŒÆ',\n",
       " 'Œ∏Œ¨ŒΩŒ±œÑŒøœÇ',\n",
       " 'ŒºŒΩŒ∑ÕÇŒºŒ±',\n",
       " 'ŒΩŒµŒ∫œÅœåœÇ',\n",
       " 'œÄŒ±œÑŒ≠œâ',\n",
       " 'œáŒ±œÅŒØŒ∂ŒøŒºŒ±Œπ',\n",
       " '·ºÄŒΩŒØœÉœÑŒ∑ŒºŒπ',\n",
       " '·ºêŒ∫'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwl_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ŒîœåŒæŒ±',\n",
       " 'Œï·ΩêŒªŒøŒ≥Œ∑œÑ·Ω∏œÇ',\n",
       " 'ŒòŒµœåœÇ',\n",
       " 'ŒòŒµ·Ω∏ŒΩ',\n",
       " 'ŒöœçœÅŒπŒµ',\n",
       " 'ŒúŒ±œÅŒØŒ±',\n",
       " 'Œ†Œ±œÑœÅœåœÇ',\n",
       " 'Œ†ŒπŒª·æ∂œÑŒøœÇ',\n",
       " 'Œ†œÅŒøœÉŒ¥ŒøŒ∫·ø∂',\n",
       " 'Œ†œåŒΩœÑŒπŒøœÇ',\n",
       " 'Œ£œÑŒ±œÖœÅœâŒ∏Œ≠ŒΩœÑŒ±',\n",
       " 'ŒßœÅŒπœÉœÑœåœÇ',\n",
       " 'Œ±·º∞ŒΩŒ≠œâ',\n",
       " 'Œ±·º∞œéŒΩ',\n",
       " 'Œ±·º¥ŒΩŒµœÉŒπœÇ',\n",
       " 'Œ≤Œ¨œÄœÑŒπœÉŒºŒ±',\n",
       " 'Œ≤Œ±œÉŒØŒªŒµŒπŒøœÇ',\n",
       " 'Œ≥ŒØŒ≥ŒΩŒøŒºŒ±Œπ',\n",
       " 'Œ≥ŒµŒΩŒµŒ¨',\n",
       " 'Œ≥ŒµŒΩŒΩŒ¨œâ',\n",
       " 'Œ≥ŒπŒ≥ŒΩœéœÉŒ∫œâ',\n",
       " 'Œ≥œÅŒ±œÜŒÆ',\n",
       " 'Œ≥·øÜ',\n",
       " 'Œ¥Œ≠Œ∑œÉŒπœÇ',\n",
       " 'Œ¥ŒØŒ¥Œ±ŒæœåŒΩ',\n",
       " 'Œ¥ŒØŒ¥œâŒºŒπ',\n",
       " 'Œ¥ŒµŒØŒ∫ŒΩœÖŒºŒπ',\n",
       " 'Œ¥ŒµŒæŒπœåœÇ',\n",
       " 'Œ¥ŒπŒ¨',\n",
       " 'Œ¥ŒπŒ∫Œ±ŒπœéŒºŒ±œÑŒ¨',\n",
       " 'Œ¥Œπ‚Äô',\n",
       " 'Œ¥ŒøŒæŒ¨Œ∂œâ',\n",
       " 'Œ¥œåŒæŒ±',\n",
       " 'Œ¥œçŒΩŒ±ŒºŒπœÇ',\n",
       " 'Œµ·º∞ŒºŒØ',\n",
       " 'Œµ·º∞œÅŒÆŒΩŒ∑',\n",
       " 'Œµ·º∞œÇ',\n",
       " 'Œµ·º∞œÉœÜŒ≠œÅœâ',\n",
       " 'Œµ·º∂ŒºŒπ',\n",
       " 'Œµ·º∑œÇ',\n",
       " 'Œµ·ΩêŒ¥ŒøŒ∫ŒØŒ±',\n",
       " 'Œµ·ΩêŒªŒøŒ≥Œ≠œâ',\n",
       " 'Œµ·ΩêŒªŒøŒ≥ŒØŒ±',\n",
       " 'Œµ·ΩêœáŒ±œÅŒπœÉœÑŒ≠œâ',\n",
       " 'Œ∂Œ¨œâ',\n",
       " 'Œ∂œâŒÆ',\n",
       " 'Œ∂œâŒøœÄŒøŒπœåœÇ',\n",
       " 'Œ∏Œ¨œÄœÑœâ',\n",
       " 'Œ∏Œ≠ŒªŒ∑ŒºŒ¨',\n",
       " 'Œ∏ŒµœåœÇ',\n",
       " 'Œ∫Œ¨Œ∏Œ∑ŒºŒ±Œπ',\n",
       " 'Œ∫Œ±ŒØ',\n",
       " 'Œ∫Œ±Œ∏Œ¨',\n",
       " 'Œ∫Œ±Œ∏ŒøŒªŒπŒ∫·Ω¥ŒΩ',\n",
       " 'Œ∫Œ±œÑŒ¨',\n",
       " 'Œ∫Œ±œÑŒ¨ŒΩœÖŒæŒπœÇ',\n",
       " 'Œ∫Œ±œÑŒ¨·ºïŒ∂ŒøŒºŒ±Œπ',\n",
       " 'Œ∫Œ±œÑŒ≠œÅœáŒøŒºŒ±Œπ',\n",
       " 'Œ∫Œ±œÑŒ±œÜŒµœçŒ≥œâ',\n",
       " 'Œ∫œÅŒØŒΩœâ',\n",
       " 'Œ∫œåœÉŒºŒøœÇ',\n",
       " 'Œ∫œçœÅŒπŒøœÇ',\n",
       " 'ŒªŒ≠Œ≥œâ',\n",
       " 'ŒªŒ±ŒªŒ≠œâ',\n",
       " 'ŒºŒ≠Œ≥Œ±œÇ',\n",
       " 'ŒºŒ≠ŒªŒªœâ',\n",
       " 'ŒºŒÆ',\n",
       " 'ŒºŒÆœÑŒ∑œÅ',\n",
       " 'ŒºŒ±Œ∫Œ±œÅŒØŒ∂œâ',\n",
       " 'ŒºŒµŒ≥Œ±ŒªœçŒΩœâ',\n",
       " 'ŒºŒµœÑŒ¨',\n",
       " 'ŒºŒøŒΩŒøŒ≥ŒµŒΩŒÆœÇ',\n",
       " 'ŒºœåŒΩŒøœÇ',\n",
       " 'ŒΩŒµŒ∫œÅœåœÇ',\n",
       " 'ŒΩ·ø¶ŒΩ',\n",
       " 'Œø·Ωê',\n",
       " 'Œø·ΩêœÅŒ±ŒΩœåœÇ',\n",
       " 'Œø·ΩóœÑŒøœÇ',\n",
       " 'œÄŒ¨ŒªŒπŒΩ',\n",
       " 'œÄŒ¨œÉœáœâ',\n",
       " 'œÄŒ±ŒΩŒ±ŒºœéŒºŒ∑œÑŒøŒΩ',\n",
       " 'œÄŒ±ŒΩœÑŒøŒ∫œÅŒ¨œÑœâœÅ',\n",
       " 'œÄŒ±œÅŒ¨',\n",
       " 'œÄŒ±œÅŒ±œÑŒµŒØŒΩœâ',\n",
       " 'œÄŒ±œÅŒ∏Œ≠ŒΩŒøœÇ',\n",
       " 'œÄŒ±œÑŒÆœÅ',\n",
       " 'œÄŒµŒπœÅŒ±œÉŒºœåœÇ',\n",
       " 'œÄŒ∑Œ≥ŒÆ',\n",
       " 'œÄŒπœÉœÑŒµœçœâ',\n",
       " 'œÄŒΩŒµ·ø¶ŒºŒ±',\n",
       " 'œÄŒøŒπŒ≠œâ',\n",
       " 'œÄŒøŒπŒ∑œÑŒÆœÇ',\n",
       " 'œÄŒøŒΩŒ∑œÅœåœÇ',\n",
       " 'œÄœÅŒøœÉŒµœçœáŒøŒºŒ±Œπ',\n",
       " 'œÄœÅŒøœÉŒ∫œÖŒΩŒ≠œâ',\n",
       " 'œÄœÅŒøœÜŒÆœÑŒ∑œÇ',\n",
       " 'œÄœÅœå',\n",
       " 'œÄœÅœåœÇ',\n",
       " 'œÄ·æ∂œÇ',\n",
       " 'œÉŒÆŒºŒµœÅŒøŒΩ',\n",
       " 'œÉŒ±œÅŒ∫œåœâ',\n",
       " 'œÉœÖŒΩŒ¥ŒøŒæŒ¨Œ∂œâ',\n",
       " 'œÉœâœÑŒÆœÅ',\n",
       " 'œÉœâœÑŒ∑œÅŒØŒ±',\n",
       " 'œÉœç',\n",
       " 'œÉœçŒΩ',\n",
       " 'œÑŒ≠ŒªŒøœÇ',\n",
       " 'œÑŒØŒ∫œÑœâ',\n",
       " 'œÑŒØŒºŒπŒøœÇ',\n",
       " 'œÑŒµ',\n",
       " 'œÑœÅŒØœÑŒøœÇ',\n",
       " 'œÖ·º±œåœÇ',\n",
       " 'œÜŒ¨ŒøœÇ',\n",
       " 'œÜœÖŒªŒ¨œÉœÉœâ',\n",
       " 'œÜœéœÇ',\n",
       " 'œàœÖœáŒÆ',\n",
       " '·ºÄŒ¥ŒπŒ¨œÜŒ∏ŒøœÅŒøœÇ',\n",
       " '·ºÄŒµŒØ',\n",
       " '·ºÄŒµŒπŒºŒ±Œ∫Œ¨œÅŒπœÉœÑŒøŒΩ',\n",
       " '·ºÄŒ∏Œ¨ŒΩŒ±œÑŒøœÇ',\n",
       " '·ºÄŒªŒ∑Œ∏ŒÆœÇ',\n",
       " '·ºÄŒªŒ∑Œ∏ŒπŒΩœåœÇ',\n",
       " '·ºÄŒªŒªŒ¨',\n",
       " '·ºÄŒºŒΩœåœÇ',\n",
       " '·ºÄŒΩŒ¨œÉœÑŒ±œÉŒπœÇ',\n",
       " '·ºÄŒΩŒ≠œÅœáŒøŒºŒ±Œπ',\n",
       " '·ºÄŒΩŒØœÉœÑŒ∑ŒºŒπ',\n",
       " '·ºÄŒΩŒ±ŒºŒ¨œÅœÑŒ∑œÑŒøœÇ',\n",
       " '·ºÄœÄŒøœÉœÑŒøŒªŒπŒ∫·Ω¥ŒΩ',\n",
       " '·ºÄœÄœå',\n",
       " '·ºÄœÉœçŒ≥Œ∫œÅŒπœÑŒøœÇ',\n",
       " '·ºÄœÜŒØŒ∑ŒºŒπ',\n",
       " '·ºÄœåœÅŒ±œÑŒøœÇ',\n",
       " '·ºÅŒ≥ŒπŒ¨Œ∂œâ',\n",
       " '·ºÅŒºŒ±œÅœÑŒ¨ŒΩœâ',\n",
       " '·ºÅŒºŒ±œÅœÑŒØŒ±',\n",
       " '·ºÅŒºœåœÇ',\n",
       " '·ºÑŒΩŒ∏œÅœâœÄŒøœÇ',\n",
       " '·ºÑœÅœÑŒøœÇ',\n",
       " '·ºÑœÜŒµœÉŒπœÇ',\n",
       " '·ºÖŒ≥ŒπŒøœÇ',\n",
       " '·ºàŒ≥œÅŒØœÄœÄŒ±œÇ',\n",
       " '·ºçŒ≥ŒπŒøœÇ',\n",
       " '·ºêŒ≥œé',\n",
       " '·ºêŒ∫',\n",
       " '·ºêŒ∫Œ∫ŒªŒ∑œÉŒØŒ±',\n",
       " '·ºêŒ∫œÄŒøœÅŒµœçœâ',\n",
       " '·ºêŒªŒµŒ≠œâ',\n",
       " '·ºêŒªœÄŒØŒ∂œâ',\n",
       " '·ºêŒΩ',\n",
       " '·ºêŒΩŒ±ŒΩŒ∏œÅœâœÄŒ≠œâ',\n",
       " '·ºêœÄŒØ',\n",
       " '·ºêœÄŒπŒøœçœÉŒπŒøœÇ',\n",
       " '·ºêœÄŒøœÖœÅŒ¨ŒΩŒπŒøœÇ',\n",
       " '·ºîŒªŒµœåœÇ',\n",
       " '·ºîŒΩŒ¥ŒøŒæŒøœÇ',\n",
       " '·ºîœÅœáŒøŒºŒ±Œπ',\n",
       " '·ºïŒ∫Œ±œÉœÑŒøœÇ',\n",
       " '·º°ŒºŒ≠œÅŒ±',\n",
       " '·º°ŒºŒ≠œÑŒµœÅŒøœÇ',\n",
       " '·º∞Œ¨ŒøŒºŒ±Œπ',\n",
       " '·ºµŒ∑ŒºŒπ',\n",
       " '·º∏Œ∑œÉŒø·ø¶',\n",
       " '·º∏Œ∑œÉŒø·ø¶œÇ',\n",
       " '·º∏œÉœáœÖœÅœåœÇ',\n",
       " '·ΩÄœÜŒµŒØŒªŒ∑ŒºŒ±',\n",
       " '·ΩÄœÜŒµŒπŒªŒ≠œÑŒ∑œÇ',\n",
       " '·ΩÅ',\n",
       " '·ΩÅŒºŒøŒªŒøŒ≥Œ≠œâ',\n",
       " '·ΩÅŒºŒøŒøœçœÉŒπŒøœÇ',\n",
       " '·ΩÅœÅŒ¨œâ',\n",
       " '·ΩÅœÅŒ±œÑœåœÇ',\n",
       " '·ΩÑŒΩŒøŒºŒ¨',\n",
       " '·ΩÑŒΩœÑœâœÇ',\n",
       " '·ΩÖœÑŒπ',\n",
       " '·ΩëœÄŒ≠œÅ',\n",
       " '·ΩïœàŒπœÉœÑŒøœÇ',\n",
       " '·Ω°œÇ',\n",
       " '·ø•œçŒøŒºŒ±Œπ'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ŒΩŒµŒ∫œÅœåœÇ'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_up(notes[188])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Œ∫Œ±·Ω∂',\n",
       " '·ºçŒ≥ŒπŒøœÇ',\n",
       " '·ΩÅ',\n",
       " 'ŒöœçœÅŒπŒµ',\n",
       " '·º°Œº·æ∂œÇ',\n",
       " 'œÉŒøœÖ',\n",
       " 'œÑŒø·ø¶',\n",
       " '·ºêŒΩ',\n",
       " 'œÑ·Ω∏',\n",
       " 'Œµ·º∞œÇ',\n",
       " 'Œµ·º∂',\n",
       " '·ºêŒªŒ≠Œ∑œÉŒøŒΩ',\n",
       " 'ŒòŒµœåœÇ',\n",
       " 'œÉŒµ',\n",
       " '·ºÄŒ∏Œ¨ŒΩŒ±œÑŒøœÇ',\n",
       " 'ŒºŒµ',\n",
       " '·º°Œº·ø∂ŒΩ',\n",
       " '·º°',\n",
       " '·º∏œÉœáœÖœÅœåœÇ',\n",
       " 'œÑ·Ω∞',\n",
       " 'Œ¥ŒØŒ¥Œ±ŒæœåŒΩ',\n",
       " 'Œï·ΩêŒªŒøŒ≥Œ∑œÑ·Ω∏œÇ',\n",
       " 'œÑ·Ω∏ŒΩ',\n",
       " 'œÑ·Ω¥ŒΩ',\n",
       " 'œÑŒø·øñœÇ',\n",
       " '·º°Œº·øñŒΩ',\n",
       " 'Œ¥ŒπŒ∫Œ±ŒπœéŒºŒ±œÑŒ¨',\n",
       " 'œÑŒø·Ω∫œÇ',\n",
       " '·ΩÑŒΩŒøŒºŒ¨',\n",
       " 'œÉ·Ω∫',\n",
       " 'Œ¥·Ω∏œÇ',\n",
       " 'œÑ·øÜœÇ',\n",
       " 'ŒΩ·ø¶ŒΩ',\n",
       " 'œÜœâœÑŒØ',\n",
       " 'œÉŒø·Ω∂',\n",
       " 'œÄŒ±œÅ·Ω∞',\n",
       " 'œÄŒøŒπŒµ·øñŒΩ',\n",
       " 'œÉ·Ω≤',\n",
       " 'œÄœÅ·Ω∏œÇ',\n",
       " 'œàœÖœáŒÆŒΩ',\n",
       " 'œÉŒ≠',\n",
       " '·º†ŒªœÄŒØœÉŒ±ŒºŒµŒΩ',\n",
       " 'Œ∫Œ±Œ∏Œ¨œÄŒµœÅ',\n",
       " 'œÑŒ±œçœÑ·øÉ',\n",
       " '·º°ŒºŒ≠œÅ·æ≥',\n",
       " 'œÑ·øá',\n",
       " 'Œ±·º∞·ø∂ŒΩŒøœÇ',\n",
       " '·º°ŒºŒ≠œÅŒ±ŒΩ',\n",
       " '·ºëŒ∫Œ¨œÉœÑŒ∑ŒΩ',\n",
       " '·º∏Œ∑œÉŒø·ø¶œÇ',\n",
       " 'Œ¥ŒµŒæŒπ·æ∑',\n",
       " 'œÑ·Ω∞œÇ',\n",
       " '·º∏Œ∑œÉŒø·ø¶',\n",
       " 'ŒºŒµŒ≥Œ¨ŒªŒ∑ŒΩ',\n",
       " 'Œ¥Œπ·Ω∞',\n",
       " '·ºÄŒΩŒ∏œÅœéœÄŒøŒπœÇ',\n",
       " 'Œµ·º∞œÅŒÆŒΩŒ∑',\n",
       " 'Œ≥·øÜœÇ',\n",
       " '·ΩëœàŒØœÉœÑŒøŒπœÇ',\n",
       " '·ΩçœÑŒπ',\n",
       " 'Œ†Œ±œÑœÅœåœÇ',\n",
       " '·ºêœÄ·Ω∂',\n",
       " 'ŒîœåŒæŒ±',\n",
       " '·Ω°œÇ',\n",
       " 'Œ≤Œ±œÉŒπŒªŒµŒØŒ±',\n",
       " 'Œ∏Œ≠ŒªŒ∑ŒºŒ¨',\n",
       " '·ΩÖœÑŒπ',\n",
       " 'ŒºŒøœÖ',\n",
       " '·ºîŒªŒµœåœÇ',\n",
       " 'œÑ·ø∂ŒΩ',\n",
       " 'ŒºœåŒΩŒøœÇ',\n",
       " 'Œ∫œåœÉŒºŒøœÖ',\n",
       " 'Œ¥œåŒæŒ±ŒΩ',\n",
       " 'œÉŒøŒπ',\n",
       " 'œÜ·ø∂œÇ',\n",
       " 'œÑ·ø∑',\n",
       " '·ºÄŒºŒÆŒΩ',\n",
       " 'Œ¥œåŒæŒ±',\n",
       " 'Œ¥œçŒΩŒ±ŒºŒπœÇ',\n",
       " '·ºêœÉœÑŒπŒΩ',\n",
       " 'œÉŒø·ø¶',\n",
       " '·ºÄœÄ·Ω∏',\n",
       " '·ºÄŒªŒª·Ω∞',\n",
       " '·º°ŒºŒµ·øñœÇ',\n",
       " 'Œ≥ŒµŒΩŒµ·æ∑',\n",
       " 'œÄŒøŒΩŒ∑œÅŒø·ø¶',\n",
       " '·ø•·ø¶œÉŒ±Œπ',\n",
       " 'œÄŒµŒπœÅŒ±œÉŒºœåŒΩ',\n",
       " 'Œµ·º∞œÉŒµŒΩŒ≠Œ≥Œ∫·øÉœÇ',\n",
       " 'Œº·Ω¥',\n",
       " 'œÉœâœÑŒÆœÅ',\n",
       " '·ΩÄœÜŒµŒπŒªŒ≠œÑŒ∑œÇ',\n",
       " '·ºÄœÜŒØŒ∑ŒºŒπ',\n",
       " '·ΩÄœÜŒµŒØŒªŒ∑ŒºŒ±',\n",
       " 'œÉŒÆŒºŒµœÅŒøŒΩ',\n",
       " 'Œµ·ΩêœáŒ±œÅŒπœÉœÑŒ≠œâ',\n",
       " 'Œ¥ŒøŒæŒ¨Œ∂œâ',\n",
       " 'œÄœÅŒøœÉŒ∫œÖŒΩŒ≠œâ',\n",
       " 'Œµ·ΩêŒªŒøŒ≥ŒØŒ±',\n",
       " 'Œµ·ΩêŒ¥ŒøŒ∫ŒØŒ±',\n",
       " 'œÉœç',\n",
       " 'Œ¥ŒµŒØŒ∫ŒΩœÖŒºŒπ',\n",
       " 'ŒºŒøŒΩŒøŒ≥ŒµŒΩŒÆœÇ',\n",
       " '·ºêŒªŒµŒ≠œâ',\n",
       " 'œÄŒ±ŒΩœÑŒøŒ∫œÅŒ¨œÑœâœÅ',\n",
       " 'Œ∏ŒµœåœÇ',\n",
       " '·ºêœÄŒøœÖœÅŒ¨ŒΩŒπŒøœÇ',\n",
       " '·ºàŒ≥œÅŒØœÄœÄŒ±œÇ',\n",
       " '·ºÅŒºŒ±œÅœÑŒØŒ±',\n",
       " 'œÖ·º±œåœÇ',\n",
       " '·ºÄŒºŒΩœåœÇ',\n",
       " 'œÄŒΩŒµ·ø¶ŒºŒ±',\n",
       " 'ŒßœÅŒπœÉœÑœåœÇ',\n",
       " 'Œ∫Œ¨Œ∏Œ∑ŒºŒ±Œπ',\n",
       " 'Œ¥Œ≠Œ∑œÉŒπœÇ',\n",
       " 'œÄœÅŒøœÉŒµœçœáŒøŒºŒ±Œπ',\n",
       " 'Œ±·º¥ŒΩŒµœÉŒπœÇ',\n",
       " 'Œµ·ΩêŒªŒøŒ≥Œ≠œâ',\n",
       " 'Œ∫Œ±œÑŒ¨',\n",
       " 'Œ∫œçœÅŒπŒøœÇ',\n",
       " 'Œ∫Œ±œÑŒ¨ŒΩœÖŒæŒπœÇ',\n",
       " 'œÜœÖŒªŒ¨œÉœÉœâ',\n",
       " '·ºÄŒΩŒ±ŒºŒ¨œÅœÑŒ∑œÑŒøœÇ',\n",
       " '·ºêœÄŒØ',\n",
       " 'Œ≥ŒØŒΩŒøŒºŒ±Œπ',\n",
       " 'Œ±·º∞ŒΩŒ≠œâ',\n",
       " 'œÄŒ±œÑŒÆœÅ',\n",
       " '·º∞Œ¨ŒøŒºŒ±Œπ',\n",
       " 'ŒªŒ≠Œ≥œâ',\n",
       " '·ºêŒ≥œé',\n",
       " '·ºÅŒºŒ±œÅœÑŒ¨ŒΩœâ',\n",
       " 'Œ∫Œ±œÑŒ±œÜŒµœçŒ≥œâ',\n",
       " 'Œ∂œâŒÆ',\n",
       " 'œÄŒ∑Œ≥ŒÆ',\n",
       " 'Œ≥ŒπŒΩœéœÉŒ∫œâ',\n",
       " 'œÄŒ±œÅŒ±œÑŒµŒØŒΩœâ',\n",
       " '·ΩÅœÅŒ¨œâ',\n",
       " 'Œ±·º∞œéŒΩ',\n",
       " '·ºÄŒµŒØ',\n",
       " '·ºîœÅœáŒøŒºŒ±Œπ',\n",
       " '·ºÅŒ≥ŒπŒ¨Œ∂œâ',\n",
       " 'Œø·ΩêœÅŒ±ŒΩœåœÇ',\n",
       " '·ºêœÄŒπŒøœçœÉŒπŒøœÇ',\n",
       " '·ºÑœÅœÑŒøœÇ',\n",
       " '·ºÄŒªŒ∑Œ∏·ø∂œÇ',\n",
       " 'ŒºŒ±Œ∫Œ±œÅŒØŒ∂ŒµŒπŒΩ',\n",
       " '·ºÄŒµŒπŒºŒ±Œ∫Œ¨œÅŒπœÉœÑŒøŒΩ',\n",
       " 'œÄŒ±ŒΩŒ±ŒºœéŒºŒ∑œÑŒøŒΩ',\n",
       " 'ŒºŒ∑œÑŒ≠œÅŒ±',\n",
       " 'œÑŒπŒºŒπœâœÑŒ≠œÅŒ±ŒΩ',\n",
       " '·ºÄœÉœÖŒ≥Œ∫œÅŒØœÑœâœÇ',\n",
       " '·ºêŒΩŒ¥ŒøŒæŒøœÑŒ≠œÅŒ±ŒΩ',\n",
       " '·ºÄŒ¥ŒπŒ±œÜŒ∏œåœÅœâœÇ',\n",
       " 'ŒòŒµ·Ω∏ŒΩ',\n",
       " 'œÑŒµŒ∫Œø·ø¶œÉŒ±ŒΩ',\n",
       " '·ΩÑŒΩœÑœâœÇ',\n",
       " 'ŒºŒµŒ≥Œ±ŒªœçŒΩŒøŒºŒµŒΩ',\n",
       " '·ºÖŒ≥ŒπŒøœÇ',\n",
       " 'Œ¥Œπ‚Äô',\n",
       " '·ºÄŒªŒ∑Œ∏ŒπŒΩœåœÇ',\n",
       " '·ºÄŒºŒÆŒΩ',\n",
       " '·ºÄŒΩŒ¨œÉœÑŒ±œÉŒπœÇ',\n",
       " '·ºÄŒΩŒ≠œÅœáŒøŒºŒ±Œπ',\n",
       " '·ºÄŒΩŒØœÉœÑŒ∑ŒºŒπ',\n",
       " '·ºÄœåœÅŒ±œÑŒøœÇ',\n",
       " '·ºÑœÜŒµœÉŒπœÇ',\n",
       " 'Œ≤Œ¨œÄœÑŒπœÉŒºŒ±',\n",
       " 'Œ≤Œ±œÉŒπŒªŒµŒØŒ±',\n",
       " 'Œ≥ŒµŒΩŒΩŒ¨œâ',\n",
       " 'Œ≥œÅŒ±œÜŒÆ',\n",
       " 'Œµ·º∞œÇ',\n",
       " 'Œµ·º∑œÇ',\n",
       " '·ºêŒ∫',\n",
       " '·ºêŒ∫Œ∫ŒªŒ∑œÉŒØŒ±',\n",
       " '·ºêŒ∫œÄŒøœÅŒµœçŒøŒºŒ±Œπ',\n",
       " 'Œ∂Œ¨œâ',\n",
       " '·º°ŒºŒ≠œÑŒµœÅŒøœÇ',\n",
       " 'Œ∏Œ¨œÄœÑœâ',\n",
       " 'Œ∏ŒµœåœÇ',\n",
       " '·º∏Œ∑œÉŒø·ø¶œÇ',\n",
       " 'Œ∫Œ±Œ∏Œ≠Œ∂ŒøŒºŒ±Œπ',\n",
       " 'Œ∫Œ±œÑŒ≠œÅœáŒøŒºŒ±Œπ',\n",
       " 'Œ∫œÅŒØŒΩœâ',\n",
       " 'Œ∫œçœÅŒπŒøœÇ',\n",
       " 'ŒªŒ±ŒªŒ≠œâ',\n",
       " 'ŒúŒ±œÅŒØŒ±',\n",
       " 'ŒºŒ≠ŒªŒªœâ',\n",
       " 'ŒºŒµœÑŒ¨',\n",
       " 'ŒΩŒµŒ∫œÅœåœÇ',\n",
       " '·ΩÅŒºŒøŒªŒøŒ≥Œ≠œâ',\n",
       " '·ΩÅŒºŒøŒøœçœÉŒπŒøœÇ',\n",
       " '·ΩÅœÅŒ±œÑœåœÇ',\n",
       " 'Œø·Ωê',\n",
       " 'Œø·Ωó',\n",
       " 'Œø·ΩêœÅŒ±ŒΩœåœÇ',\n",
       " 'œÄŒ¨ŒªŒπŒΩ',\n",
       " 'œÄŒ±œÅŒ∏Œ≠ŒΩŒøœÇ',\n",
       " 'œÄ·æ∂œÇ',\n",
       " 'œÄŒ¨œÉœáœâ',\n",
       " 'œÄŒ±œÑŒÆœÅ',\n",
       " 'Œ†ŒπŒª·æ∂œÑŒøœÇ',\n",
       " 'œÄŒπœÉœÑŒµœçœâ',\n",
       " 'œÄŒΩŒµ·ø¶ŒºŒ±',\n",
       " 'œÄŒøŒπŒ∑œÑŒÆœÇ',\n",
       " 'Œ†œåŒΩœÑŒπŒøœÇ',\n",
       " 'œÄœÅœå',\n",
       " 'œÄœÅŒøœÜŒÆœÑŒ∑œÇ',\n",
       " 'œÉœçŒΩ',\n",
       " 'œÉœÖŒΩŒ¥ŒøŒæŒ¨Œ∂œâ',\n",
       " 'œÉœâœÑŒ∑œÅŒØŒ±',\n",
       " 'œÑŒ≠',\n",
       " 'œÑŒ≠ŒªŒøœÇ',\n",
       " 'œÑœÅŒØœÑŒøœÇ',\n",
       " 'œÖ·º±œåœÇ',\n",
       " '·ΩëœÄŒ≠œÅ',\n",
       " 'œÜ·ø∂œÇ',\n",
       " 'ŒßœÅŒπœÉœÑœåœÇ',\n",
       " '·ºêŒΩŒ±ŒΩŒ∏œÅœâœÄŒÆœÉŒ±ŒΩœÑŒ±',\n",
       " 'Œ£œÑŒ±œÖœÅœâŒ∏Œ≠ŒΩœÑŒ±',\n",
       " 'Œ∂œâŒøœÄŒøŒπœåŒΩ',\n",
       " 'Œ∫Œ±Œ∏ŒøŒªŒπŒ∫·Ω¥ŒΩ',\n",
       " '·ºÄœÄŒøœÉœÑŒøŒªŒπŒ∫·Ω¥ŒΩ',\n",
       " 'Œ†œÅŒøœÉŒ¥ŒøŒ∫·ø∂',\n",
       " 'œÉŒ±œÅŒ∫œâŒ∏Œ≠ŒΩœÑŒ±']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [(1,2,3), 4, 5, (6,7,8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
